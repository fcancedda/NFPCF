{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" FINE TUNING MODEL WITHOUT FAIRNESS OR DIFFERENTIAL PRIVACY \"\"\"\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import NCF\n",
    "from fairness_measures import Measures\n",
    "\n",
    "import data\n",
    "from importlib import reload\n",
    "reload(data)\n",
    "from data import AttributeData, TargetData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_k = 10\n",
    "\n",
    "learning_rate = .001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% CONSTANTS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscocancedda/Documents/Scool/NFPCF/data.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/franciscocancedda/Documents/Scool/NFPCF/data.py:222: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  item_id = clean[['ojob']].drop_duplicates()\n"
     ]
    }
   ],
   "source": [
    "# targets= TargetData()\n",
    "data = AttributeData()\n",
    "m = Measures()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD DATA AND FAIRNESS FUNCTIONS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "ncf = NCF(6040, 3952, emb_size, hidden_layers, output_size).to(device)\n",
    "ncf.load_state_dict(torch.load(\"models/preTrained_NCF\"))\n",
    "\n",
    "# FETCH NUMBER OF UNIQUE CAREERS\n",
    "n_careers = data.num_jobs\n",
    "\n",
    "# CHANGE EMBEDDING SIZE TO FIT SENSITIVE INFO\n",
    "# ncf.like_emb = nn.Embedding(n_careers, emb_size).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "user_embeds = ncf.user_emb.weight.data.cpu().detach().numpy()\n",
    "user_embeds = user_embeds.astype('float')\n",
    "\n",
    "\n",
    "''' COMPUTE GENDER EMBEDDING '''\n",
    "gender_embed = np.zeros((2,user_embeds.shape[1]))\n",
    "num_users_x_group = np.zeros((2, 1))\n",
    "\n",
    "for i in range(data.train.shape[0]):\n",
    "    u = data.train['uid'].iloc[i]\n",
    "    if data.train['gender'].iloc[i] == 0:\n",
    "        gender_embed[0] +=  user_embeds[u]\n",
    "        num_users_x_group[0] += 1.0\n",
    "    else:\n",
    "        gender_embed[1] +=  user_embeds[u]\n",
    "        gender_embed[1] += 1.0\n",
    "        num_users_x_group[1] += 1.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD USER EMBEDDING AND WEIGH BY GENDER\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.08833937, 0.09018802, 0.0879173 , 0.09250274, 0.08757752,\n        0.08920489, 0.08567962, 0.08674757, 0.08743061, 0.09037649,\n        0.08797264, 0.09147833, 0.09224037, 0.09063672, 0.09083148,\n        0.0854365 , 0.08963342, 0.0895668 , 0.08999261, 0.08771025,\n        0.08754062, 0.09176309, 0.0865631 , 0.09061284, 0.0840617 ,\n        0.08517442, 0.08619777, 0.08566763, 0.09502302, 0.09061725,\n        0.08765419, 0.08803402, 0.08960038, 0.08851412, 0.08357468,\n        0.0895203 , 0.09011151, 0.08341624, 0.08742171, 0.09232834,\n        0.0885374 , 0.08852077, 0.08717989, 0.08961292, 0.08994275,\n        0.09027861, 0.09130058, 0.0902064 , 0.08928831, 0.08815647,\n        0.09112686, 0.08360929, 0.09076972, 0.08280671, 0.09078205,\n        0.08712893, 0.08788025, 0.08945807, 0.0916801 , 0.09049211,\n        0.08781245, 0.08455281, 0.08489517, 0.08846074, 0.08586793,\n        0.08481279, 0.08591463, 0.08852091, 0.0919617 , 0.09057988,\n        0.08801147, 0.09121689, 0.08738795, 0.08788589, 0.09401182,\n        0.08814151, 0.08866359, 0.08788551, 0.08931895, 0.08681896,\n        0.08736531, 0.08859415, 0.08898962, 0.08640467, 0.08689482,\n        0.09304924, 0.08347231, 0.08696466, 0.08742288, 0.08577202,\n        0.08527726, 0.08913173, 0.08835476, 0.08997734, 0.08928587,\n        0.090011  , 0.08631017, 0.08625461, 0.08516598, 0.08692122,\n        0.08950774, 0.08647552, 0.09190098, 0.08989946, 0.08643074,\n        0.09140442, 0.08485215, 0.0866987 , 0.08647966, 0.0945284 ,\n        0.08762699, 0.08641945, 0.09094904, 0.09028924, 0.08828723,\n        0.09006176, 0.08845924, 0.08906742, 0.08792956, 0.08875835,\n        0.08726227, 0.08457953, 0.08683605, 0.08931271, 0.08761513,\n        0.0823401 , 0.0889574 , 0.0885162 ]])"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' VERTICAL BIAS'''\n",
    "gender_embed = gender_embed / num_users_x_group\n",
    "# vBias = compute_bias_direction(gender_embed)\n",
    "vBias = gender_embed[1].reshape((1,-1)) - gender_embed[0].reshape((1,-1))\n",
    "vBias = vBias / np.linalg.norm(vBias,axis=1,keepdims=1)\n",
    "\n",
    "vBias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- VERTICAL BIAS ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "''' LINEAR PROJECTION '''\n",
    "debiased_user_embeds = user_embeds\n",
    "for i in range(len(data.df)):\n",
    "    u = data.df['uid'].iloc[i]\n",
    "    debiased_user_embeds[u] = user_embeds[u] - (np.inner(user_embeds[u].reshape(1,-1),vBias)[0][0])*vBias\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- DEBIAS USERS ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "'''UPDATE USER EMBEDDINGS'''\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n",
    "\n",
    "n_careers = data.num_jobs\n",
    "\n",
    "# replace page items with career items\n",
    "ncf.like_emb = nn.Embedding(n_careers,emb_size).to(device)\n",
    "# freeze user embedding\n",
    "ncf.user_emb.weight.requires_grad=False\n",
    "\n",
    "# replace user embedding of the model with debiased embeddings\n",
    "ncf.user_emb.weight.data = torch.from_numpy(debiased_user_embeds.astype(np.float32)).to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- FINE TUNE FOR CAREER OPTIMIZATION ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "NCF(\n  (user_emb): Embedding(6040, 128)\n  (like_emb): Embedding(17, 128)\n  (fc1): Linear(in_features=256, out_features=128, bias=True)\n  (relu1): ReLU()\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (relu2): ReLU()\n  (fc3): Linear(in_features=64, out_features=32, bias=True)\n  (relu3): ReLU()\n  (fc4): Linear(in_features=32, out_features=16, bias=True)\n  (relu4): ReLU()\n  (outLayer): Linear(in_features=16, out_features=1, bias=True)\n  (out_act): Sigmoid()\n)"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "ncf.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [],
   "source": [
    "def evaluate_fine_tune(model, df_val, k, random_samples):\n",
    "    model.eval()\n",
    "    avg_hr = np.zeros((len(df_val), k))\n",
    "    avg_ndcg = np.zeros((len(df_val), k))\n",
    "\n",
    "    for i in range(len(df_val)):\n",
    "        test_df = data.add_negatives(\n",
    "            df_val,\n",
    "            item='job',\n",
    "            items=data.jobs,\n",
    "            n_samples=random_samples\n",
    "        )\n",
    "        users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.job).to(device)\n",
    "        y_hat = model(users, items)\n",
    "\n",
    "        y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "        items = items.cpu().detach().numpy().reshape((-1,))\n",
    "        map_item_score = {}\n",
    "        for j in range(len(y_hat)):\n",
    "            map_item_score[items[j]] = y_hat[j]\n",
    "        for k in range(k):\n",
    "            # Evaluate top rank list\n",
    "            ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "            gtItem = items[0]\n",
    "            avg_hr[i, k] = m.get_hit_ratio(ranklist, gtItem)\n",
    "            avg_ndcg[i, k] = m.get_ndcg(ranklist, gtItem)\n",
    "        avg_hr = np.mean(avg_hr, axis=0)\n",
    "        avg_ndcg = np.mean(avg_ndcg, axis=0)\n",
    "        return avg_hr, avg_ndcg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [],
   "source": [
    "# LOAD TRAINING DATA\n",
    "all_users = torch.LongTensor(data.train['uid'].values).to(device)\n",
    "all_items = torch.LongTensor(data.train['job'].values).to(device)\n",
    "\n",
    "# PROTECTED ATTRIBUTE\n",
    "all_genders = torch.LongTensor(data.train['gender'].values).to(device)\n",
    "# from opacus import PrivacyEngine\n",
    "#\n",
    "# privacy_engine = PrivacyEngine(\n",
    "#     ncf,\n",
    "#     sample_rate=0.01,\n",
    "#     alphas=[10, 100],\n",
    "#     noise_multiplier=1.3,\n",
    "#     max_grad_norm=1.0,\n",
    "# )\n",
    "# optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "# privacy_engine.attach(optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "def train_normal():\n",
    "    # REMOVES JOBS BASED ON THRESHOLD + SPLIT DATA\n",
    "    # train, test = data.train_test_split(train_fraction)\n",
    "    # num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "    loss = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "    final_loss = 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        j=0\n",
    "        dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0)\n",
    "\n",
    "        it_per_epoch = len(data) / batch_size\n",
    "\n",
    "        for batch in dataloader:\n",
    "            usr, jb, _, rt = batch\n",
    "            # LOAD BATCH\n",
    "            users = usr.to(device)\n",
    "            jobs = jb.to(device)  # career\n",
    "            # genders = g.to(device)\n",
    "            ratings = rt.to(device)\n",
    "\n",
    "            # PREDICTIONS\n",
    "            y_hat = ncf(users.squeeze(1), jobs.squeeze(1))\n",
    "\n",
    "            # BINARY CROSS-ENTROPY LOSS\n",
    "            loss1 = loss(y_hat, ratings.float())\n",
    "\n",
    "            predicted_probs = ncf(all_users, all_items)\n",
    "            avg_epsilon = m.compute_edf(all_genders, predicted_probs, data.num_jobs, all_items, device)\n",
    "\n",
    "            # criteroin hinge\n",
    "            loss2 = torch.max(torch.tensor(0.0).to(device), (avg_epsilon - epsilonBase))\n",
    "\n",
    "            final_loss = loss1 + fairness_thres*loss2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            final_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if j % int(1 + it_per_epoch / 10) == 0:\n",
    "                print(f\"Progress: {round(100 * j / it_per_epoch)}%\")\n",
    "            j += 1\n",
    "        ht, ndcg = evaluate_fine_tune(ncf, data.test, top_k, random_samples)\n",
    "        print(f'Hit Ratio: {ht}  NDCG: {ndcg}   LOSS1: {loss1}  LOSS2: {loss2} ')\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: job'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_44502/186168564.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'user_id'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'uid'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'like_id'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'mid'\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'rating'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mht\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mndcg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mevaluate_fine_tune\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mncf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtop_k\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;31m# train_normal()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0mht\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_44502/1247274295.py\u001B[0m in \u001B[0;36mevaluate_fine_tune\u001B[0;34m(model, df_val, k, random_samples)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m         test_df = data.add_negatives(\n\u001B[0m\u001B[1;32m      8\u001B[0m             \u001B[0mdf_val\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m             \u001B[0mitem\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'job'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/data.py\u001B[0m in \u001B[0;36madd_negatives\u001B[0;34m(self, df, item, items, n_samples)\u001B[0m\n\u001B[1;32m    185\u001B[0m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mcombine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroupby\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'uid'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m         \u001B[0mcombine\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'negatives'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcombine\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitems\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1536\u001B[0m                 \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1537\u001B[0m             )\n\u001B[0;32m-> 1538\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1539\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1540\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_gotitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mndim\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/pandas/core/base.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    230\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 232\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Column not found: {key}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    233\u001B[0m             \u001B[0msubset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m             \u001B[0mndim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msubset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Column not found: job'"
     ]
    }
   ],
   "source": [
    "ht, ndcg = evaluate_fine_tune(ncf, data.test, top_k, random_samples)\n",
    "# train_normal()\n",
    "ht.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''MEASURE THE FAIRNESS OF THE MODEL'''\n",
    "def fairness_measures(model,df_val,num_items):\n",
    "    model.eval()\n",
    "    users, items = torch.LongTensor(df_val.uid.to_numpy()).to(device), torch.LongTensor(df_val.job.to_numpy()).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    avg_epsilon = m.compute_edf(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "    U_abs = m.compute_absolute_unfairness(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "\n",
    "    avg_epsilon = avg_epsilon.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"average differential fairness: {avg_epsilon: .3f}\")\n",
    "\n",
    "    U_abs = U_abs.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"absolute unfairness: {U_abs: .3f}\")\n",
    "\n",
    "fairness_measures(ncf, data.test, n_careers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Function for evaluating fairness ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "data": {
      "text/plain": "       uid   mid  rating\n0        1   425       1\n1        4    48       1\n2        4  1337       1\n3        7   313       1\n4        8   490       1\n...    ...   ...     ...\n9943  6038  1616       1\n9944  6039   990       1\n9945  6039  1572       1\n9946  6039  3050       1\n9947  6039    48       1\n\n[9948 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>425</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>48</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1337</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>490</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9943</th>\n      <td>6038</td>\n      <td>1616</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9944</th>\n      <td>6039</td>\n      <td>990</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9945</th>\n      <td>6039</td>\n      <td>1572</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9946</th>\n      <td>6039</td>\n      <td>3050</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9947</th>\n      <td>6039</td>\n      <td>48</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9948 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(ncf.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- SAVE ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
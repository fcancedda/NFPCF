{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" FINE TUNING MODEL WITH FAIRNESS\"\"\"\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import NCF3\n",
    "from fairness_measures import Measures\n",
    "from evaluators import evaluate_model\n",
    "import data as data_parser\n",
    "from importlib import reload\n",
    "reload(data_parser)\n",
    "from data import AttributeData, TargetData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "num_layers = 4\n",
    "# hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_k = 10\n",
    "\n",
    "learning_rate = .001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% CONSTANTS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "td = TargetData()\n",
    "data = AttributeData()\n",
    "m = Measures()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD DATA AND FAIRNESS FUNCTIONS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED MODEL\n",
    "ncf = NCF3(td.num_users, td.num_movies, emb_size, num_layers, output_size).to(device)\n",
    "ncf.load_state_dict(torch.load(\"saved_models/NCF2\"))\n",
    "\n",
    "# FETCH NUMBER OF UNIQUE CAREERS\n",
    "n_careers = data.num_jobs\n",
    "\n",
    "ncf.embed_item_GMF = nn.Embedding(n_careers, emb_size).to(device)\n",
    "ncf.embed_item_GMF.weight.requires_grad = False\n",
    "\n",
    "ncf.embed_item_MLP = nn.Embedding(n_careers, emb_size * (2 ** (num_layers - 1))).to(device)\n",
    "ncf.embed_item_MLP.weight.requires_grad = False\n",
    "# CHANGE EMBEDDING SIZE TO FIT SENSITIVE INFO\n",
    "# ncf.like_emb = nn.Embedding(n_careers, emb_size).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "user_embeds = ncf.embed_user_MLP.weight.data.cpu().detach().numpy()\n",
    "user_embeds = user_embeds.astype('float')\n",
    "\n",
    "\n",
    "''' COMPUTE GENDER EMBEDDING '''\n",
    "gender_embed = np.zeros((2,user_embeds.shape[1]))\n",
    "num_users_x_group = np.zeros((2, 1))\n",
    "\n",
    "for i in range(data.train.shape[0]):\n",
    "    u = data.train['uid'].iloc[i]\n",
    "    if data.train['gender'].iloc[i] == 0:\n",
    "        gender_embed[0] +=  user_embeds[u]\n",
    "        num_users_x_group[0] += 1.0\n",
    "    else:\n",
    "        gender_embed[1] +=  user_embeds[u]\n",
    "        gender_embed[1] += 1.0\n",
    "        num_users_x_group[1] += 1.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD USER EMBEDDING AND WEIGH BY GENDER\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.03232344, 0.03123073, 0.03107457, ..., 0.03259981, 0.03171002,\n        0.03077014]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' VERTICAL BIAS'''\n",
    "gender_embed = gender_embed / num_users_x_group\n",
    "# vBias = compute_bias_direction(gender_embed)\n",
    "vBias = gender_embed[1].reshape((1,-1)) - gender_embed[0].reshape((1,-1))\n",
    "vBias = vBias / np.linalg.norm(vBias,axis=1,keepdims=1)\n",
    "\n",
    "vBias\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- VERTICAL BIAS ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21896/334395022.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;34m''' LINEAR PROJECTION '''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mdebiased_user_embeds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0muser_embeds\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0mu\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'uid'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mdebiased_user_embeds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0muser_embeds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minner\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muser_embeds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mu\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvBias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mvBias\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\NFPCF\\venv\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, attribute_name)\u001B[0m\n\u001B[0;32m     81\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 83\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "''' LINEAR PROJECTION '''\n",
    "debiased_user_embeds = user_embeds\n",
    "for i in range(len(data.data)):\n",
    "    u = data.all_data['uid'].iloc[i]\n",
    "    debiased_user_embeds[u] = user_embeds[u] - (np.inner(user_embeds[u].reshape(1,-1),vBias)[0][0])*vBias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- DEBIAS USERS ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.all_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''UPDATE USER EMBEDDINGS'''\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n",
    "\n",
    "# replace user embedding of the model with debiased embeddings\n",
    "ncf.embed_user_MLP.weight.data = torch.from_numpy(debiased_user_embeds.astype(np.float32)).to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- FINE TUNE FOR CAREER OPTIMIZATION ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "NCF3(\n  (embed_user_GMF): Embedding(4920, 128)\n  (embed_item_GMF): Embedding(17, 128)\n  (embed_user_MLP): Embedding(4920, 1024)\n  (embed_item_MLP): Embedding(17, 1024)\n  (out_act): Sigmoid()\n  (MLP_layers): Sequential(\n    (0): Dropout(p=1, inplace=False)\n    (1): Linear(in_features=2048, out_features=1024, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=1, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=True)\n    (5): ReLU()\n    (6): Dropout(p=1, inplace=False)\n    (7): Linear(in_features=512, out_features=256, bias=True)\n    (8): ReLU()\n    (9): Dropout(p=1, inplace=False)\n    (10): Linear(in_features=256, out_features=128, bias=True)\n    (11): ReLU()\n  )\n  (predict_layer): Linear(in_features=256, out_features=1, bias=True)\n)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "ncf.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# LOAD TRAINING DATA\n",
    "all_users = torch.LongTensor(data.train['uid'].values).to(device)\n",
    "all_items = torch.LongTensor(data.train['job'].values).to(device)\n",
    "\n",
    "# PROTECTED ATTRIBUTE\n",
    "all_genders = torch.LongTensor(data.train['gender'].values).to(device)\n",
    "# from opacus import PrivacyEngine\n",
    "#\n",
    "# privacy_engine = PrivacyEngine(\n",
    "#     ncf,\n",
    "#     sample_rate=0.01,\n",
    "#     alphas=[10, 100],\n",
    "#     noise_multiplier=1.3,\n",
    "#     max_grad_norm=1.0,\n",
    "# )\n",
    "# optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "# privacy_engine.attach(optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def train_normal(model):\n",
    "    # REMOVES JOBS BASED ON THRESHOLD + SPLIT DATA\n",
    "    # train, test = data.train_test_split(train_fraction)\n",
    "    # num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "    loss = nn.BCELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "    final_loss, loss1, loss2 = 0, 0, 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        j=0\n",
    "        dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0)\n",
    "\n",
    "        it_per_epoch = len(data) / batch_size\n",
    "\n",
    "        for batch in dataloader:\n",
    "            usr, jb, _, rt = batch\n",
    "            # LOAD BATCH\n",
    "            users = usr.to(device)\n",
    "            jobs = jb.to(device)  # career\n",
    "            # genders = g.to(device)\n",
    "            ratings = rt.to(device)\n",
    "\n",
    "            # PREDICTIONS\n",
    "            y_hat = model(users.squeeze(1), jobs.squeeze(1))\n",
    "\n",
    "            # BINARY CROSS-ENTROPY LOSS\n",
    "            loss1 = loss(y_hat, ratings.float())\n",
    "\n",
    "            predicted_probs = model(all_users, all_items)\n",
    "            avg_epsilon = m.compute_edf(all_genders.cpu(), predicted_probs, data.num_jobs, all_items, device)\n",
    "\n",
    "            # criteroin hinge\n",
    "            loss2 = torch.max(torch.tensor(0.0).to(device), (avg_epsilon - epsilonBase))\n",
    "\n",
    "            final_loss = loss1 + fairness_thres*loss2\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            final_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if j % int(1 + it_per_epoch / 10) == 0:\n",
    "                print(f\"\\r Epoch {i + 1}, Progress: {round(100 * j / it_per_epoch)}%\", end='', flush=True)\n",
    "            j += 1\n",
    "        ht, ndcg = evaluate_model(model, data.test[['uid', 'job']].values, top_k, random_samples, data.num_jobs, device)\n",
    "        print(f'\\nHit Ratio: {round(ht[-1], 2)}  NDCG: {round(ndcg[-1], 2)}   LOSS1: {final_loss}')\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.25187567, 0.27974277, 0.3204716 , 0.38585209,\n       0.47695606, 0.58199357, 0.67631297, 0.76956056, 0.84780279])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht, ndcg = evaluate_model(ncf, data.test[['uid', 'job']].values, top_k, random_samples, data.num_jobs, device)\n",
    "ht"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.15326902 0.27759914 0.39121115 0.49732047 0.59914255\n",
      " 0.69989282 0.76956056 0.84137192 0.89496249]  NDCG: [0.         0.15326902 0.2317126  0.2885186  0.3342174  0.37360755\n",
      " 0.40949552 0.4327181  0.45537206 0.47150443]   LOSS1: 4.7397894859313965  LOSS2: 0.2597944438457489 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.15755627 0.27867095 0.40728832 0.52411576 0.62165059\n",
      " 0.70310825 0.78135048 0.85637728 0.90782422]  NDCG: [0.         0.15755627 0.23397113 0.29827981 0.34859465 0.38632627\n",
      " 0.41534208 0.44142282 0.46509114 0.48057821]   LOSS1: 3.7208361625671387  LOSS2: 0.09305262565612793 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.13719185 0.26152197 0.39013934 0.51018221 0.62379421\n",
      " 0.71382637 0.78885316 0.85316184 0.91318328]  NDCG: [0.         0.13719185 0.21563542 0.27994411 0.33164376 0.37559488\n",
      " 0.40766498 0.43267391 0.45296104 0.4710293 ]   LOSS1: 3.5639874935150146  LOSS2: 0.07193741947412491 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.16398714 0.28188639 0.40621651 0.52411576 0.61629153\n",
      " 0.69453376 0.78135048 0.8488746  0.90996785]  NDCG: [0.         0.16398714 0.23837328 0.30053834 0.35131478 0.38697324\n",
      " 0.41484369 0.44378259 0.46508408 0.48347498]   LOSS1: 2.0915215015411377  LOSS2: 0.11868217587471008 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.14362272 0.28938907 0.39871383 0.50053591 0.61414791\n",
      " 0.70203644 0.78242229 0.85316184 0.91425509]  NDCG: [0.         0.14362272 0.23559105 0.29025343 0.33410581 0.37805693\n",
      " 0.40936346 0.43615874 0.45847459 0.47686549]   LOSS1: 1.1648889780044556  LOSS2: 0.08568434417247772 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.15326902 0.27974277 0.3869239  0.48767417 0.58842444\n",
      " 0.68381565 0.75669882 0.8306538  0.9056806 ]  NDCG: [0.         0.15326902 0.23306507 0.28665564 0.33004642 0.36902194\n",
      " 0.40300098 0.42729537 0.45062557 0.47321088]   LOSS1: 0.670183539390564  LOSS2: 0.1257723569869995 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.13719185 0.26152197 0.36977492 0.47695606 0.5755627\n",
      " 0.68274384 0.75241158 0.82958199 0.90353698]  NDCG: [0.         0.13719185 0.21563542 0.2697619  0.3159223  0.35406856\n",
      " 0.39224725 0.41546983 0.43981439 0.46207705]   LOSS1: 1.0285612344741821  LOSS2: 0.1218271255493164 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.1511254  0.2733119  0.39121115 0.48981779 0.61093248\n",
      " 0.69131833 0.7642015  0.83494105 0.90032154]  NDCG: [0.         0.1511254  0.2282165  0.28716612 0.32963369 0.37648725\n",
      " 0.40512127 0.42941566 0.4517315  0.47141299]   LOSS1: 0.18525488674640656  LOSS2: 0.09172718971967697 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.14362272 0.27545552 0.39764202 0.52197213 0.59914255\n",
      " 0.69346195 0.78135048 0.85101822 0.91854234]  NDCG: [0.         0.14362272 0.22679996 0.2878932  0.34143927 0.37129286\n",
      " 0.40489011 0.43418629 0.45616401 0.4764908 ]   LOSS1: 0.10079599916934967  LOSS2: 0.12070509791374207 \n",
      "Progress: 0%\n",
      "Progress: 11%\n",
      "Progress: 21%\n",
      "Progress: 32%\n",
      "Progress: 42%\n",
      "Progress: 53%\n",
      "Progress: 63%\n",
      "Progress: 74%\n",
      "Progress: 85%\n",
      "Progress: 95%\n",
      "Hit Ratio: [0.         0.15755627 0.29367631 0.40300107 0.50589496 0.6034298\n",
      " 0.70418006 0.78135048 0.84780279 0.91211147]  NDCG: [0.         0.15755627 0.24343846 0.29810083 0.34241482 0.38014645\n",
      " 0.41603442 0.44175789 0.46272126 0.4820801 ]   LOSS1: 2.712099075317383  LOSS2: 0.11518224328756332 \n"
     ]
    }
   ],
   "source": [
    "train_normal(ncf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Measures' object has no attribute 'fairness_measures'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21896/219976245.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;34m'''MEASURE THE FAIRNESS OF THE MODEL'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfairness_measures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mncf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mall_genders\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_careers\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Measures' object has no attribute 'fairness_measures'"
     ]
    }
   ],
   "source": [
    "'''MEASURE THE FAIRNESS OF THE MODEL'''\n",
    "\n",
    "m.fairness_measures(ncf, data.test, all_genders.cpu(), n_careers, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Function for evaluating fairness ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "torch.save(ncf.state_dict(), \"saved_models/NFCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- SAVE ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3d09f4f2",
   "language": "python",
   "display_name": "PyCharm (NFPCF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
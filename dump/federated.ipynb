{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\n",
    "# --- Class definition of the MLP model ---\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    ''' Constructs a Multi-Layer Perceptron model'''\n",
    "\n",
    "    def __init__(self, num_users=6040, num_items=3952, embeddings=64):\n",
    "        torch.manual_seed(0)\n",
    "        super().__init__()\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.item_embedding = nn.Embedding(num_items, embeddings).cuda()\n",
    "\n",
    "        # MLP layers\n",
    "        self.l1 = nn.Linear(embeddings * 2, 64).cuda()\n",
    "        self.l2 = nn.Linear(64, 32).cuda()\n",
    "        self.l3 = nn.Linear(32, 16).cuda()\n",
    "        self.l4 = nn.Linear(16, 1, bias=False).cuda()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # map to embeddings\n",
    "        embedding1 = self.user_embedding(user).squeeze(1)\n",
    "        embedding2 = self.item_embedding(item).squeeze(1)\n",
    "\n",
    "        # Concatenation of the embedding layers\n",
    "        out = torch.cat((embedding1, embedding2), 1)\n",
    "\n",
    "        # feed through the MLP layers\n",
    "        out = F.relu(self.l1(out))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = F.relu(self.l3(out))\n",
    "\n",
    "        # output between 0 and 1\n",
    "        out = torch.sigmoid(self.l4(out))\n",
    "        return out\n",
    "\n",
    "\n",
    "# --- Class definition of the GMF model ---\n",
    "\n",
    "class GMF(nn.Module):\n",
    "    ''' Constructs a Generalized Matrix Factorization model '''\n",
    "\n",
    "    def __init__(self, num_users=6040, num_items=3952, embeddings=64):\n",
    "        torch.manual_seed(0)\n",
    "        super().__init__()\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.item_embedding = nn.Embedding(num_items, embeddings).cuda()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # map to embeddings\n",
    "        embedding1 = self.user_embedding(user).squeeze(1)\n",
    "        embedding2 = self.item_embedding(item).squeeze(1)\n",
    "\n",
    "        # Elementwise multiplication\n",
    "        GMF_layer = embedding1 * embedding2\n",
    "\n",
    "        # sum GMF layer\n",
    "        out = torch.sum(GMF_layer, 1).unsqueeze_(1)\n",
    "\n",
    "        # output between 0 and 1\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class RatingsData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, num_negatives=3, validation=True, num_users=6040, num_items=3952):\n",
    "        np.random.seed(0)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        # Reads the data from file\n",
    "        r = pd.read_table(csv_file, sep=\"::\",\n",
    "                          names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"], engine='python')\n",
    "\n",
    "        self.length = len(r)  # Number of interactions in the data set\n",
    "        self.ratings, self.test = self.load_as_matrix(r,\n",
    "                                                      validation)  # Interactions as a matrix structured as ((user,item) rating)\n",
    "        self.num_negatives = num_negatives  # Number of negative instances per positive instance\n",
    "        # Lists of the users and items to train and test on\n",
    "        self.user_input, self.item_input, self.rating = [], [], []\n",
    "        self.get_train_instances(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_input)  # Length of the data to train on\n",
    "\n",
    "    def __getitem__(self, idx):  # idx is the index of the training instance\n",
    "        # User and item id as tensors\n",
    "        user = torch.LongTensor([self.user_input[idx] - 1])  # -1 so that indexing starts from 0\n",
    "        movie = torch.LongTensor([self.item_input[idx] - 1])\n",
    "        # Output label and loss weight as tensors\n",
    "        p = torch.ones(1)\n",
    "        w = torch.ones(1)\n",
    "        # Larger weight for higher ratings\n",
    "        w[0] = 1\n",
    "        p[0] = min(1, self.rating[idx])\n",
    "\n",
    "        return user, movie, p, w\n",
    "\n",
    "    def load_as_matrix(self, ratings, validation):\n",
    "        # Interactions as dictionary of keys (matrix)\n",
    "        mat = sp.dok_matrix((self.num_users + 1, self.num_items + 1), dtype=np.float32)\n",
    "        last_u = 1\n",
    "        last_i = 0\n",
    "        second_last_u = 0\n",
    "        second_last_i = 0\n",
    "        test_item = []\n",
    "\n",
    "        for i in range(self.length):\n",
    "            user, item, rating = int(ratings[\"user_id\"][i]), int(ratings[\"movie_id\"][i]), int(ratings[\"rating\"][i])\n",
    "            if user > last_u:\n",
    "                if validation:\n",
    "                    mat.pop((last_u, last_i))\n",
    "                    test_item.append(second_last_i)\n",
    "                    mat.pop((second_last_u, second_last_i))\n",
    "                else:\n",
    "                    test_item.append(last_i)\n",
    "                    mat.pop((last_u, last_i))\n",
    "\n",
    "            if (rating > 0):\n",
    "                # mat[user, item] = 1.0\n",
    "                mat[user, item] = rating\n",
    "\n",
    "            second_last_u = last_u\n",
    "            second_last_i = last_i\n",
    "            last_u = user\n",
    "            last_i = item\n",
    "\n",
    "        if validation:\n",
    "            mat.pop((last_u, last_i))\n",
    "            test_item.append(second_last_i)\n",
    "            mat.pop((second_last_u, second_last_i))\n",
    "        else:\n",
    "            test_item.append(last_i)\n",
    "            mat.pop((last_u, last_i))\n",
    "\n",
    "        return mat, test_item\n",
    "\n",
    "    # if validation is True the last two interaction for each user will not be\n",
    "    # part of the training instances, and the penultimate will be used as test\n",
    "    # if False only the last interaction for each user will be left out and used as test\n",
    "    def get_train_instances(self, seed=0):\n",
    "        np.random.seed(seed)\n",
    "        train = self.ratings\n",
    "        self.user_input, self.item_input, self.rating = [], [], []\n",
    "\n",
    "        for (u, i) in train.keys():\n",
    "\n",
    "            # positive instance\n",
    "            self.user_input.append(u)\n",
    "            self.item_input.append(i)\n",
    "            self.rating.append(int(train[u, i]))\n",
    "\n",
    "            # Generate negative instances\n",
    "            for t in range(self.num_negatives):\n",
    "                j = np.random.randint(1, self.num_items + 1)\n",
    "                # Keep generating items if the item has been interacted with\n",
    "                while (u, j) in train:\n",
    "                    j = np.random.randint(1, self.num_items + 1)\n",
    "                self.user_input.append(u)\n",
    "                self.item_input.append(j)\n",
    "                self.rating.append(0)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- CLass definition for the MovieLens data set ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test_negatives(filename):\n",
    "    # Read items (from file) that each user has not interacted with and add them to a list\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        negatives = []\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            for x in arr:\n",
    "                if x != \"\\n\":\n",
    "                    negatives.append(int(x))\n",
    "            line = f.readline()\n",
    "\n",
    "    return negatives\n",
    "\n",
    "\n",
    "def rank(l, item):\n",
    "    # rank of the test item in the list of negative instances\n",
    "    # returns the number of elements that the test item is bigger than\n",
    "\n",
    "    index = 0\n",
    "    for element in l:\n",
    "        if element > item:\n",
    "            index += 1\n",
    "            return index\n",
    "        index += 1\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_test_tensor(user, test_item, test_neg):\n",
    "    # Prepare the test data points as tensors\n",
    "\n",
    "    test_item = test_item[user - 1]\n",
    "\n",
    "    test_negatives = test_neg[100 * (user - 1):100 * user]\n",
    "\n",
    "    user_tensor = torch.LongTensor([user - 1])\n",
    "    user_test = torch.stack((user_tensor, user_tensor))\n",
    "    item_input = test_negatives[0] - 1\n",
    "    item_input = torch.LongTensor([item_input])\n",
    "\n",
    "    user_tensor.unsqueeze_(0)\n",
    "\n",
    "    item_test = torch.LongTensor([test_item - 1])\n",
    "    item_test = torch.stack((item_test, item_input))\n",
    "\n",
    "    for i in range(1, 100):\n",
    "        item_input = test_negatives[i] - 1\n",
    "        item_input = torch.LongTensor([item_input])\n",
    "        item_input.unsqueeze_(0)\n",
    "\n",
    "        user_test = torch.cat((user_test, user_tensor), 0)\n",
    "        item_test = torch.cat((item_test, item_input), 0)\n",
    "\n",
    "    return user_test, item_test\n",
    "\n",
    "\n",
    "def evaluate_model(model, data, validation=True, num_users=6040):\n",
    "    # Evaluates the model and returns HR@10 and NDCG@10\n",
    "\n",
    "    device = \"cuda\"\n",
    "    test_items = data.test\n",
    "    if validation:\n",
    "        test_neg = test_negatives(\"validation_negatives.csv\")\n",
    "    else:\n",
    "        test_neg = test_negatives(\"test_negatives.csv\")\n",
    "    hits = 0\n",
    "    ndcg = 0\n",
    "\n",
    "    for i in range(1, num_users + 1):\n",
    "        user_test, item_test = get_test_tensor(i, test_items, test_neg)\n",
    "\n",
    "        user_test = user_test.to(device)\n",
    "        item_test = item_test.to(device)\n",
    "\n",
    "        l = model(user_test, item_test)\n",
    "        l = l.tolist()\n",
    "        l = sum(l, [])\n",
    "        first = l.pop(0)\n",
    "\n",
    "        l.sort()\n",
    "\n",
    "        ranking = rank(l, first)\n",
    "\n",
    "        if ranking > 90:\n",
    "            hits += 1\n",
    "            ndcg += np.log(2) / np.log(len(user_test) - ranking + 1)\n",
    "\n",
    "    hr = hits / data.num_users\n",
    "    ndcg = ndcg / data.num_users\n",
    "    return hr, ndcg\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Functions for testing ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def fit(model, data, batch_size, epochs, lr, wd, validation=True, verbose=True):\n",
    "    device = \"cuda\"\n",
    "    # Defining optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    it_per_epoch = len(data) / batch_size\n",
    "    tot_loss = 0\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Start training loop\n",
    "    for e in range(epochs):\n",
    "        print(\"Starting epoch \", e + 1)\n",
    "        data.get_train_instances(seed=e)\n",
    "\n",
    "        dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0)\n",
    "        t1 = time.time()\n",
    "        i = 0\n",
    "        for batch in dataloader:\n",
    "            # Load tensors of users, movies, outputs and loss weights\n",
    "            u, m, p, w = batch\n",
    "            # move tensors to cuda\n",
    "            u = u.to(device)\n",
    "            m = m.to(device)\n",
    "            p = p.to(device)\n",
    "            w = w.to(device)\n",
    "\n",
    "            # make predictions\n",
    "            p_pred = model(u, m)\n",
    "            # Calculate mean loss\n",
    "            loss_fn = torch.nn.BCELoss(weight=w, reduction=\"mean\")\n",
    "            loss = loss_fn(p_pred, p)\n",
    "            tot_loss += loss.item()\n",
    "\n",
    "            # Backpropagate the output and updates model parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i += 1\n",
    "\n",
    "            # Print progress\n",
    "            if i % int(1 + it_per_epoch / 10) == 0 and verbose:\n",
    "                print(\"Progress: \", round(100 * i / it_per_epoch), \"%\")\n",
    "\n",
    "        # Epoch metrics\n",
    "        t2 = time.time()\n",
    "        print(\"Epoch time:\", round(t2 - t1), \"seconds\")\n",
    "        print(\"Loss:\", tot_loss / i)\n",
    "        print(\"Evaluating model...\")\n",
    "        HR, NDCG = evaluate_model(model, data, validation=validation)\n",
    "        print(\"HR@10:\", HR)\n",
    "        print(\"NDCG@10\", NDCG)\n",
    "        tot_loss = 0\n",
    "        print()\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Function for training ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Done\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_10771/435342590.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mweight_decay\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMLP\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;31m# for GMF: model = GMF()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_10771/688400173.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, num_users, num_items, embeddings)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;31m# user and item embedding layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muser_embedding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEmbedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_users\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem_embedding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mEmbedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_items\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mcuda\u001B[0;34m(self, device)\u001B[0m\n\u001B[1;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m         \"\"\"\n\u001B[0;32m--> 680\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    682\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    591\u001B[0m             \u001B[0;31m# `with torch.no_grad():`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 593\u001B[0;31m                 \u001B[0mparam_applied\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    594\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    679\u001B[0m         \"\"\"\n\u001B[0;32m--> 680\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    681\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    682\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mT\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/torch/cuda/__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    206\u001B[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001B[1;32m    207\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_cuda_getDeviceCount'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Torch not compiled with CUDA enabled\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_cudart\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             raise AssertionError(\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print(\"Processing data...\")\n",
    "data = RatingsData(\"MovieLens/ratings.dat\", num_negatives=3, validation=False)\n",
    "print(\"Done\")\n",
    "\n",
    "learning_rate = pow(10, -2)\n",
    "weight_decay = 0\n",
    "\n",
    "model = MLP()\n",
    "# for GMF: model = GMF()\n",
    "\n",
    "# train and test\n",
    "fit(model=model, data=data, batch_size=256, epochs=10, lr=learning_rate, wd=weight_decay, validation=False,\n",
    "    verbose=True)\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Main script for training---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
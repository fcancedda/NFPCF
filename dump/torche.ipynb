{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "# conda install pytorch torchvision cudatoolkit=11.3 -c pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from data import DataGenerator\n",
    "\n",
    "data = DataGenerator()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_likes, embed_size, num_hidden, output_size):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_size)\n",
    "        self.like_emb = nn.Embedding(num_likes,embed_size)\n",
    "        self.fc1 = nn.Linear(embed_size*2, num_hidden[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(num_hidden[0], num_hidden[1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(num_hidden[1], num_hidden[2])\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(num_hidden[2], num_hidden[3])\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.outLayer = nn.Linear(num_hidden[3], output_size)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.like_emb(v)\n",
    "        out = torch.cat([U,V], dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.outLayer(out)\n",
    "        out = self.out_act(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001\n",
    "batch_size = 2048\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 100\n",
    "top_K = 10\n",
    "\n",
    "preTrained_NCF = NCF(data.num_users, data.num_movies, emb_size, hidden_layers, output_size).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "NCF(\n  (user_emb): Embedding(6040, 128)\n  (like_emb): Embedding(3952, 128)\n  (fc1): Linear(in_features=256, out_features=128, bias=True)\n  (relu1): ReLU()\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (relu2): ReLU()\n  (fc3): Linear(in_features=64, out_features=32, bias=True)\n  (relu3): ReLU()\n  (fc4): Linear(in_features=32, out_features=16, bias=True)\n  (relu4): ReLU()\n  (outLayer): Linear(in_features=16, out_features=1, bias=True)\n  (out_act): Sigmoid()\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''SET MODEL TO TRAINING MODE'''\n",
    "import torch.optim as optim\n",
    "\n",
    "# set loss = BINARY CROSS ENTROPY\n",
    "criterion = nn.BCELoss()\n",
    "# ADAM Optimizer\n",
    "optimizer = optim.Adam(preTrained_NCF.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "preTrained_NCF.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "'''TRAIN MODEL ( MINI BATCH )'''\n",
    "num_batches = np.int64(np.floor(data.train.shape[0] / batch_size))\n",
    "for i in range(num_epochs):\n",
    "    j = 0\n",
    "    for batch in np.array_split(data.train, num_batches):\n",
    "        batch_df = data.add_negatives(batch[['uid', 'mid', 'rating']], n_samples=num_negatives)\n",
    "        users = torch.LongTensor(batch_df.uid.to_numpy()).to(device)\n",
    "        items = torch.LongTensor(batch_df.mid.to_numpy()).to(device)\n",
    "        ratings = torch.FloatTensor(batch_df.rating.to_numpy()).to(device)\n",
    "        y_hat = preTrained_NCF(users, items)\n",
    "        loss = criterion(y_hat, ratings.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f'epoch: {i + 1} \\nbatch: {j} out of: {num_batches} \\naverage loss: {loss.item()}\\n')\n",
    "        # j += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "297       5\n387      15\n421      23\n426      28\n442      31\n       ... \n295    3727\n345    3743\n446    3785\n276    3792\n281    3798\nName: mid, Length: 197, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train[data.train.uid==4].mid.sort_values(ascending=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train():\n",
    "    train = data.add_negatives(data.train[['uid', 'mid', 'rating']], n_samples=4)\n",
    "    users = torch.LongTensor(train.uid.to_numpy()).to(device)\n",
    "    items = torch.LongTensor(train.mid.to_numpy()).to(device)\n",
    "    ratings = torch.FloatTensor(train.rating.to_numpy()).to(device).unsqueeze(1)\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        y_hat = preTrained_NCF(users, items)\n",
    "        loss = criterion(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'loss: {loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(model, df_val:pd.DataFrame, top_K, random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val), top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val), top_K))\n",
    "    test_df = data.add_negatives(\n",
    "        df_val,\n",
    "        n_samples=random_samples\n",
    "    )\n",
    "    gp = test_df.groupby('uid')\n",
    "    for g in gp:\n",
    "        for k in range(top_K):\n",
    "            users, items = torch.LongTensor(g.uid).to(device), torch.LongTensor(g.mid).to(device)\n",
    "            y_hat = model(users, items)\n",
    "            y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "            test_item_input = items.cpu().detach().numpy().reshape((-1,))\n",
    "            map_item_score = dict(zip(test_item_input, y_hat))\n",
    "\n",
    "    for i in range(df_val.shape[0]):\n",
    "        for k in range(top_K):\n",
    "            test_df = data.add_negatives(\n",
    "                pd.DataFrame(data.test.iloc[i]).T,\n",
    "                n_samples=random_samples\n",
    "            )\n",
    "            users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.mid).to(device)\n",
    "            y_hat = model(users, items)\n",
    "            y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "            test_item_input = items.cpu().detach().numpy().reshape((-1,))\n",
    "            map_item_score = dict(zip(test_item_input, y_hat))\n",
    "            # Evaluate top rank list\n",
    "            ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "            gtItem = test_item_input[0]\n",
    "            for item in ranklist:\n",
    "                if item==gtItem:\n",
    "                    avg_HR[i, k] = 1\n",
    "                    avg_NDCG[i, k] = math.log(2) / math.log(i+2)\n",
    "                else:\n",
    "                    avg_HR[i, k] = 0\n",
    "                    avg_NDCG[i, k] = 0\n",
    "    avg_HR = np.mean(avg_HR, axis=0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis=0)\n",
    "    return avg_HR, avg_NDCG\n",
    "\n",
    "def evaluate(model, df_val:pd.DataFrame, k=10):\n",
    "    test_df = data.add_negatives(df_val, n_samples=random_samples)\n",
    "    users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.mid).to(device)\n",
    "    y_hat = model(users, items)\n",
    "    test_df['score'] = y_hat.detach.numpy().reshape((-1,))\n",
    "    grouped = test_df.copy(deep=True)\n",
    "    grouped['ranked'] = grouped.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "    grouped.sort_values(['uid', 'rank'], inplace=True)\n",
    "    top_k = grouped[grouped['rank']<=k]\n",
    "    test_in_top_k = top_k[top_k['rating'] == 1]\n",
    "    hr = test_in_top_k.shape[0] / data.num_users\n",
    "    test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(lambda x: np.log(2)/np.log(1 + x))\n",
    "    ndcg = test_in_top_k.ndcg.sum() / data.num_users\n",
    "    return hr, ndcg\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.save(preTrained_NCF.state_dict(), \"models/preTrained_NCF\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# debiased_NCF = NCF(data.num_users, data.num_movies, emb_size, hidden_layers, output_size).to(device)\n",
    "# debiased_NCF.load_state_dict(torch.load(\"trained-models/preTrained_NCF\"))\n",
    "# debiased_NCF.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import constants\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def features():\n",
    "    df = pd.read_csv('MovieLens/users.dat',\n",
    "                     sep='::',\n",
    "                     header=None,\n",
    "                     names=['uid', 'gender', 'age', 'job', 'zip'],\n",
    "                     engine='python')\n",
    "    df.drop(columns=['uid'], inplace=True)\n",
    "    df.index.rename('uid', inplace=True)\n",
    "    df.gender = pd.get_dummies(df.gender, drop_first=True)  # 0:F, 1:M\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "features = features()\n",
    "\n",
    "# complete = pd.merge(df, data.df, how=' outer', on='uid')\n",
    "# complete.drop(columns=['date', 'latest', 'zip'], inplace=True)\n",
    "# gender_embed = compute_gender_direction(train_data, train_protected_attributes, users_embed)\n",
    "# S = 0 indicates male and S = 1 indicates female"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# see constants for more info\n",
    "drop = [0, 10, 13, 19]\n",
    "\n",
    "clean = features[~features['job'].isin(drop)]\n",
    "\n",
    "clean['rating'] = 1\n",
    "num_users = clean.uid.nunique()\n",
    "# num_movies = clean.mid.nunique()\n",
    "num_jobs = clean.job.nunique()\n",
    "\n",
    "new_job_index = np.arange(num_jobs)\n",
    "item_id = clean[['job']].drop_duplicates()\n",
    "item_id['njob'] = np.arange(num_jobs)\n",
    "clean = pd.merge(clean, item_id, on=['job'], how='left')\n",
    "clean.job = clean.njob\n",
    "clean.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(clean)) < 0.7\n",
    "\n",
    "train = clean[msk]\n",
    "test = clean[~msk]\n",
    "\n",
    "clean.info()  # 1476+3444 = 4920"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' GET USER EMBEDDING '''\n",
    "user_embeds = preTrained_NCF.user_emb.weight.data.cpu().detach().numpy()\n",
    "user_embeds = user_embeds.astype('float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' COMPUTE GENDER EMBEDDING '''\n",
    "gender_embed = np.zeros((2,user_embeds.shape[1]))\n",
    "num_users_x_group = np.zeros((2, 1))\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    u = train['uid'].iloc[i]\n",
    "    if train['gender'].iloc[i] == 0:\n",
    "        gender_embed[0] +=  user_embeds[u]\n",
    "        num_users_x_group[0] += 1.0\n",
    "    else:\n",
    "        gender_embed[1] +=  user_embeds[u]\n",
    "        gender_embed[1] += 1.0\n",
    "        num_users_x_group[1] += 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' VERTICAL BIAS'''\n",
    "gender_embed = gender_embed / num_users_x_group\n",
    "# vBias = compute_bias_direction(gender_embed)\n",
    "vBias = gender_embed[1].reshape((1,-1)) - gender_embed[0].reshape((1,-1))\n",
    "vBias = vBias / np.linalg.norm(vBias,axis=1,keepdims=1)\n",
    "\n",
    "vBias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' LINEAR PROJECTION '''\n",
    "debiased_user_embeds = user_embeds\n",
    "\n",
    "\n",
    "for i in range(len(clean)):\n",
    "    u = clean['uid'].iloc[i]\n",
    "    debiased_user_embeds[u] = user_embeds[u] - (np.inner(user_embeds[u].reshape(1,-1),vBias)[0][0])*vBias\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''UPDATE USER EMBEDDINGS'''\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n",
    "\n",
    "n_careers = clean.job.nunique()\n",
    "# replace page items with career items\n",
    "preTrained_NCF.like_emb = nn.Embedding(n_careers,emb_size).to(device)\n",
    "# freeze user embedding\n",
    "preTrained_NCF.user_emb.weight.requires_grad=False\n",
    "\n",
    "# replace user embedding of the model with debiased embeddings\n",
    "preTrained_NCF.user_emb.weight.data = torch.from_numpy(debiased_user_embeds.astype(np.float32)).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% fine-tune to career recommendation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''OPTIMIZE'''\n",
    "# fair_fine_tune_model(DF_NCF,train_data, num_epochs, learning_rate,batch_size,num_negatives,n_careers,train_gender,fairness_thres,epsilonBase, unsqueeze=True)\n",
    "emb_size = 128\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_k = 10\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(preTrained_NCF.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "preTrained_NCF.train()\n",
    "\n",
    "torch.save(preTrained_NCF.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''FAIR FINE TUNING MODEL'''\n",
    "all_users = torch.LongTensor(train['uid'].values).to(device)\n",
    "all_items = torch.LongTensor(train['job'].values).to(device)\n",
    "all_genders = torch.LongTensor(train['gender'].values).to(device)\n",
    "\n",
    "from fairness_measures import Measures\n",
    "\n",
    "m = Measures()\n",
    "num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    j = 1\n",
    "    for batch in np.array_split(train, num_batches):\n",
    "        batch_df = data.add_negatives(\n",
    "            df=batch[['uid', 'job', 'rating']],\n",
    "            item='job',\n",
    "            items=set(clean.job.unique()),\n",
    "            n_samples=4\n",
    "        )\n",
    "        print(batch_df.head())\n",
    "        users = torch.LongTensor(batch_df.uid.to_numpy()).to(device)\n",
    "        items = torch.LongTensor(batch_df.job.to_numpy()).to(device)\n",
    "        ratings = torch.FloatTensor(batch_df.rating.to_numpy()).to(device)\n",
    "        print(items)\n",
    "        y_hat = preTrained_NCF(users, items)\n",
    "\n",
    "        loss1 = criterion(y_hat, ratings.unsqueeze(1))\n",
    "\n",
    "        predicted_probs = preTrained_NCF(all_users, all_items)\n",
    "        avg_epsilon = m.computeEDF(all_genders,predicted_probs,n_careers,all_items,device)\n",
    "        print(avg_epsilon)\n",
    "        #criteroin hinge\n",
    "        loss2 = torch.max(torch.tensor(0.0).to(device), (avg_epsilon-epsilonBase))\n",
    "\n",
    "        loss = loss1 + fairness_thres*loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'epoch: {i + 1} \\nbatch: {j} out of: {num_batches} \\naverage loss: {loss.item()}\\n')\n",
    "        j+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(preTrained_NCF.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "def evaluate_fine_tune(model,df_val,top_K,random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val),top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val),top_K))\n",
    "\n",
    "    # for i in range(len(df_val)):\n",
    "    test_df = data.add_negatives(\n",
    "        df_val,\n",
    "        item='job',\n",
    "        items=set(clean.job.unique()),\n",
    "        n_samples=random_samples\n",
    "    )\n",
    "    users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.job).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "    items = items.cpu().detach().numpy().reshape((-1,))\n",
    "    map_item_score = {}\n",
    "    for j in range(len(y_hat)):\n",
    "        map_item_score[items[j]] = y_hat[j]\n",
    "    for k in range(top_K):\n",
    "        # Evaluate top rank list\n",
    "        ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "        gtItem = items[0]\n",
    "        avg_HR[i,k] = getHitRatio(ranklist, gtItem)\n",
    "        avg_NDCG[i,k] = getNDCG(ranklist, gtItem)\n",
    "    avg_HR = np.mean(avg_HR, axis = 0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis = 0)\n",
    "    return avg_HR, avg_NDCG\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''EVALUATE TUNED MODEL'''\n",
    "avg_HR_DF_NCF, avg_NDCG_DF_NCF = evaluate_fine_tune(preTrained_NCF, test, top_K, random_samples)\n",
    "\n",
    "avg_HR_DF_NCF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''MEASURE THE FAIRNESS OF THE MODEL'''\n",
    "def fairness_measures(model,df_val,num_items):\n",
    "    model.eval()\n",
    "    users, items = torch.LongTensor(df_val.uid.to_numpy()).to(device), torch.LongTensor(df_val.job.to_numpy()).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    avg_epsilon = m.computeEDF(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "    U_abs = m.compute_absolute_unfairness(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "\n",
    "    avg_epsilon = avg_epsilon.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"average differential fairness: {avg_epsilon: .3f}\")\n",
    "\n",
    "    U_abs = U_abs.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"absolute unfairness: {U_abs: .3f}\")\n",
    "\n",
    "fairness_measures(preTrained_NCF,test,n_careers)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3d09f4f2",
   "language": "python",
   "display_name": "PyCharm (NFPCF)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
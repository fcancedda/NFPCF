{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import TargetData\n",
    "\n",
    "d = TargetData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         uid   mid  rating\n764867  4555   620       1\n379365  2218    26       1\n785872  4702   873       1\n669771  4027  1336       1\n364645  2123  2756       1\n533913  3298   184       1\n720345  4312  2077       1\n405020  2426   620       1\n246144  1488  1594       1\n5522      38   184       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>764867</th>\n      <td>4555</td>\n      <td>620</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>379365</th>\n      <td>2218</td>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>785872</th>\n      <td>4702</td>\n      <td>873</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>669771</th>\n      <td>4027</td>\n      <td>1336</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>364645</th>\n      <td>2123</td>\n      <td>2756</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>533913</th>\n      <td>3298</td>\n      <td>184</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>720345</th>\n      <td>4312</td>\n      <td>2077</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>405020</th>\n      <td>2426</td>\n      <td>620</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>246144</th>\n      <td>1488</td>\n      <td>1594</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5522</th>\n      <td>38</td>\n      <td>184</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.train.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        uid_old  mid_old  rating                date   uid   mid  latest\n0             1     1193       1 2000-12-31 22:12:40     0     0    42.0\n1             1      661       1 2000-12-31 22:35:09     0     1    23.0\n2             1      914       1 2000-12-31 22:32:48     0     2    28.0\n3             1     3408       1 2000-12-31 22:04:35     0     3    47.0\n4             1     2355       1 2001-01-06 23:38:11     0     4     4.0\n...         ...      ...     ...                 ...   ...   ...     ...\n999606     6040     1091       1 2000-04-26 02:35:41  6039   772   161.0\n999607     6040     1094       1 2000-04-25 23:21:27  6039  1106   293.0\n999608     6040      562       1 2000-04-25 23:19:06  6039   365   305.0\n999609     6040     1096       1 2000-04-26 02:20:48  6039   152   234.0\n999610     6040     1097       1 2000-04-26 02:19:29  6039    26   246.0\n\n[999611 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid_old</th>\n      <th>mid_old</th>\n      <th>rating</th>\n      <th>date</th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>latest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1193</td>\n      <td>1</td>\n      <td>2000-12-31 22:12:40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>661</td>\n      <td>1</td>\n      <td>2000-12-31 22:35:09</td>\n      <td>0</td>\n      <td>1</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>914</td>\n      <td>1</td>\n      <td>2000-12-31 22:32:48</td>\n      <td>0</td>\n      <td>2</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3408</td>\n      <td>1</td>\n      <td>2000-12-31 22:04:35</td>\n      <td>0</td>\n      <td>3</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2355</td>\n      <td>1</td>\n      <td>2001-01-06 23:38:11</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>999606</th>\n      <td>6040</td>\n      <td>1091</td>\n      <td>1</td>\n      <td>2000-04-26 02:35:41</td>\n      <td>6039</td>\n      <td>772</td>\n      <td>161.0</td>\n    </tr>\n    <tr>\n      <th>999607</th>\n      <td>6040</td>\n      <td>1094</td>\n      <td>1</td>\n      <td>2000-04-25 23:21:27</td>\n      <td>6039</td>\n      <td>1106</td>\n      <td>293.0</td>\n    </tr>\n    <tr>\n      <th>999608</th>\n      <td>6040</td>\n      <td>562</td>\n      <td>1</td>\n      <td>2000-04-25 23:19:06</td>\n      <td>6039</td>\n      <td>365</td>\n      <td>305.0</td>\n    </tr>\n    <tr>\n      <th>999609</th>\n      <td>6040</td>\n      <td>1096</td>\n      <td>1</td>\n      <td>2000-04-26 02:20:48</td>\n      <td>6039</td>\n      <td>152</td>\n      <td>234.0</td>\n    </tr>\n    <tr>\n      <th>999610</th>\n      <td>6040</td>\n      <td>1097</td>\n      <td>1</td>\n      <td>2000-04-26 02:19:29</td>\n      <td>6039</td>\n      <td>26</td>\n      <td>246.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>999611 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 5358 watched these movies:\n",
      "movies in train [0, 1, 3, 4, 5]\n",
      "\tmovies in test [136]\n",
      "*** 0 Leaks Found ***\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "# movies grouped by user\n",
    "def all_movies_by_usr(train, test):\n",
    "    movies_all = zip(train.groupby('uid'), test.groupby('uid'))\n",
    "    return [(set(tr[1].mid.tolist()), set(te[1].mid.tolist())) if tr[1].uid.iloc[0] == te[1].uid.iloc[0] else '' for tr, te in movies_all]\n",
    "\n",
    "# movies in train and movies in test for each is user\n",
    "# user0 = None\n",
    "def check_for_leaks(train, test):\n",
    "    # x = 0\n",
    "    leaks = 0\n",
    "    u = choice(range(test.uid.nunique()))\n",
    "    for i, (tr, te) in enumerate( all_movies_by_usr(train, test)):\n",
    "        if i == u:\n",
    "            # tr.add(25)  # add test movie to train\n",
    "            print(f\"User: {u} watched these movies:\")\n",
    "            print(f\"movies in train {sorted(list(tr)[:5])}\")\n",
    "            print(f\"\\tmovies in test {sorted(list(te)[:5])}\")\n",
    "            if tr.intersection(te):\n",
    "                print(f'user: {i} has {tr.intersection(te)} in both train/test')\n",
    "                leaks += 1\n",
    "    if leaks > 1:\n",
    "        print(f\"*** {leaks} Leaks ***\")\n",
    "    elif leaks == 1:\n",
    "        print(f\"*** {leaks} Leak ***\")\n",
    "    else:\n",
    "        print('*** 0 Leaks Found ***')\n",
    "\n",
    "u = check_for_leaks(d.train, d.test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscocancedda/Documents/Scool/NFPCF/data.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['rating'] = 1\n",
      "/Users/franciscocancedda/Documents/Scool/NFPCF/data.py:224: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['uid'] = clean.uid - 1\n"
     ]
    }
   ],
   "source": [
    "from torch import LongTensor\n",
    "from data import AttributeData\n",
    "features = AttributeData()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       uid  gender  age  ojob  rating  job\n0        0       1   56    16       1    0\n1        1       1   25    15       1    1\n2        2       1   45     7       1    2\n3        3       1   25    20       1    3\n4        4       0   50     9       1    4\n...    ...     ...  ...   ...     ...  ...\n4915  6033       0   25     1       1    5\n4916  6034       0   25    15       1    1\n4917  6035       0   45     1       1    5\n4918  6036       0   56     1       1    5\n4919  6038       1   25     6       1   16\n\n[4920 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>ojob</th>\n      <th>rating</th>\n      <th>job</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>56</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>25</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>45</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n      <td>25</td>\n      <td>20</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>50</td>\n      <td>9</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4915</th>\n      <td>6033</td>\n      <td>0</td>\n      <td>25</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4916</th>\n      <td>6034</td>\n      <td>0</td>\n      <td>25</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4917</th>\n      <td>6035</td>\n      <td>0</td>\n      <td>45</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4918</th>\n      <td>6036</td>\n      <td>0</td>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4919</th>\n      <td>6038</td>\n      <td>1</td>\n      <td>25</td>\n      <td>6</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>4920 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "6040"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.merge(d.df, features.df, on=['uid', 'uid'], how='left')\n",
    "\n",
    "df.uid.nunique()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999611 entries, 0 to 999610\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   uid_old   999611 non-null  int64         \n",
      " 1   mid_old   999611 non-null  int64         \n",
      " 2   rating_x  999611 non-null  int8          \n",
      " 3   date      999611 non-null  datetime64[ns]\n",
      " 4   uid       999611 non-null  int64         \n",
      " 5   mid       999611 non-null  int64         \n",
      " 6   latest    999611 non-null  float64       \n",
      " 7   gender    828114 non-null  float64       \n",
      " 8   age       828114 non-null  float64       \n",
      " 9   ojob      828114 non-null  float64       \n",
      " 10  rating_y  828114 non-null  float64       \n",
      " 11  job       828114 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), int64(4), int8(1)\n",
      "memory usage: 92.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "4920"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = pd.merge(d.df,features.df, on=['uid', 'uid'], how='right')\n",
    "fd.uid.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid_old  mid_old  rating                date  gender  age  job_old  uid  \\\n",
      "0        2     1357       5 2000-12-31 21:38:29       1   56       16    0   \n",
      "1        2     3068       4 2000-12-31 21:43:20       1   56       16    0   \n",
      "2        2     1537       4 2000-12-31 21:53:40       1   56       16    0   \n",
      "3        2      647       3 2000-12-31 21:49:11       1   56       16    0   \n",
      "4        2     2194       4 2000-12-31 21:48:17       1   56       16    0   \n",
      "\n",
      "   mid  job  \n",
      "0    0    0  \n",
      "1    1    0  \n",
      "2    2    0  \n",
      "3    3    0  \n",
      "4    4    0  \n",
      "ratings 8.178212881088257\n",
      "features 0.030310869216918945\n",
      "merge 0.13698911666870117\n",
      "negatives 9.804809093475342\n",
      "total 18.15032196044922\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from time import time\n",
    "\n",
    "class LoadData(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        t1 = time()\n",
    "        self.ratings = self._load_ratings()\n",
    "        t2 = time()\n",
    "        self.user_features = self._load_features()\n",
    "        t3 = time()\n",
    "        self.fd = pd.merge(self.ratings,self.user_features, on=['uid', 'uid'], how='right')\n",
    "        t4 = time()\n",
    "        self.fd = self._reset_index(self.fd, ['uid', 'mid', 'job'])\n",
    "        print(self.fd.head())\n",
    "        self.train, self.test = self._train_test_split()\n",
    "        movies = set(self.fd.mid.unique())\n",
    "        self.tr = self.add_negatives(self.train, items = movies, n_samples=5)\n",
    "        self.te = self.add_negatives(self.test, items= movies, tr=self.train, n_samples=100)\n",
    "        self.testing_tensors = self.parse_testing(self.te)\n",
    "\n",
    "        t6 = time()\n",
    "        print('ratings', t2 - t1)\n",
    "        print('features', t3 - t2)\n",
    "        print('merge', t4 - t3)\n",
    "        print('negatives', t6 - t4)\n",
    "        print('total',t6-t1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tr.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        u, m, r = self.tr[['uid', 'mid', 'rating']].iloc[item]\n",
    "        return LongTensor([u]), LongTensor([m]), LongTensor([r])\n",
    "\n",
    "    @staticmethod\n",
    "    def add_negatives(df: pd.DataFrame, item: str = 'mid', items=None, tr = None, n_samples: int = 4):\n",
    "        if items is None:\n",
    "            items = set(df[item].unique())\n",
    "\n",
    "        def user_movies(uid, mid):\n",
    "            train_movies = set()\n",
    "            if tr is not None:\n",
    "                train_movies = set(tr[tr.uid==uid].mid.unique())\n",
    "                if not train_movies:\n",
    "                    print(' no movies in train found', uid)\n",
    "            return sample(list(items - train_movies - mid), n_samples)\n",
    "\n",
    "        df['rating'] = np.int8(1)\n",
    "        combine = df.groupby('uid')[item].apply(set).reset_index()\n",
    "        combine['negatives'] = combine.apply(lambda x: user_movies(x.uid ,x.mid), axis=1)\n",
    "\n",
    "        s = combine.apply(lambda x: pd.Series(x.negatives, dtype=np.int16), axis=1).stack().reset_index()\n",
    "        s.rename(columns={'level_0': 'uid', 0: item}, inplace=True)\n",
    "        s.drop(['level_1'], axis=1, inplace=True)\n",
    "        s['rating'] = np.int8(0)\n",
    "        s.uid = s.uid.astype(np.int16)\n",
    "\n",
    "        # complete = pd.merge([df, s], how='left', on='uid').sort_values(by=['uid', item])\n",
    "        complete = pd.concat([df, s]).sort_values(by=['uid', item])\n",
    "        return complete.reset_index(drop=True)\n",
    "\n",
    "    def _train_test_split(self):\n",
    "        self.fd['latest'] = self.fd.groupby(['uid'])['date'].rank(method='first', ascending=False)\n",
    "        test_bool = self.fd.latest <= 1\n",
    "        test = self.fd[test_bool]\n",
    "        train = self.fd[~test_bool]\n",
    "        return (\n",
    "                    train[['uid', 'mid']], test[['uid', 'mid']]\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _reset_index(df, cols):\n",
    "        for col in cols:\n",
    "            old_col = col + '_old'\n",
    "            df.rename(columns={col: old_col}, inplace=True)\n",
    "            user_id = df[[old_col]].drop_duplicates().reindex()\n",
    "            user_id[col] = np.arange(len(user_id))\n",
    "            df = pd.merge(df, user_id, on=[old_col], how='left')\n",
    "        return df\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_ratings(min_ratings=5):\n",
    "        df = pd.read_csv('MovieLens/ratings.dat',\n",
    "                         sep='::',\n",
    "                         header=None,\n",
    "                         names=['uid', 'mid', 'rating', 'date'],\n",
    "                         parse_dates=['date'],\n",
    "                         date_parser=lambda x: pd.to_datetime(x, unit='s', origin='unix'),\n",
    "                         engine='python')\n",
    "\n",
    "        # DROP MOVIES WITH LESS THAN 5 RATINGS\n",
    "        s = df.groupby(['mid']).size()\n",
    "        low_n_ratings = s[s < min_ratings].reset_index().mid.tolist()\n",
    "        return df[~df.mid.isin(low_n_ratings)]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_features():\n",
    "        df = pd.read_csv('MovieLens/users.dat',\n",
    "                         sep='::',\n",
    "                         header=None,\n",
    "                         names=['uid', 'gender', 'age', 'job', 'zip'],\n",
    "                         engine='python')\n",
    "        df.gender = pd.get_dummies(df.gender, drop_first=True)  # 0:F, 1:M\n",
    "        drop = [0, 10, 13, 19]\n",
    "\n",
    "        clean = df[~df['job'].isin(drop)]\n",
    "        return clean.drop(columns=['zip'])\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_testing(df):\n",
    "        test = df.sort_values(by=['uid', 'rating'], ascending=False)\n",
    "        users, movies, outputs = [], [], []\n",
    "        for _, u in test.groupby('uid'):\n",
    "            users.append(LongTensor(u.uid.to_numpy()))\n",
    "            # users.append(LongTensor([u.uid.values]))\n",
    "            movies.append(LongTensor(u.mid.to_numpy()))\n",
    "            # movies.append(LongTensor([u.mid.values]))\n",
    "            outputs.append(LongTensor(u.rating.to_numpy()))\n",
    "            # outputs.append(LongTensor([u.rating.values]))\n",
    "        return users, movies, outputs\n",
    "\n",
    "\n",
    "data = LoadData()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: 2157 watched these movies:\n",
      "movies in train [11, 16, 257, 904, 2306]\n",
      "\tmovies in test [1030, 1033, 1543, 3079, 3080]\n",
      "*** 0 Leaks Found ***\n"
     ]
    }
   ],
   "source": [
    "check_for_leaks(data.tr, data.te)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = .05\n",
    "\n",
    "emb_size = 128  # LATENT DIM\n",
    "\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "\n",
    "random_samples = 100\n",
    "num_negatives = 4\n",
    "top_k = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from models import NCF\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_users = data.tr.uid.nunique()\n",
    "n_movies = data.tr.mid.nunique()\n",
    "ncf = NCF(n_users, n_movies, emb_size, hidden_layers, output_size).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch  1\n",
      "Progress: 70%"
     ]
    }
   ],
   "source": [
    "from evaluators import eval_model\n",
    "optimizer = torch.optim.SGD(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "it_per_epoch = len(data) / batch_size\n",
    "\n",
    "loss = 0\n",
    "for i in range(num_epochs):\n",
    "    ncf.train()\n",
    "    print(\"Starting epoch \", i + 1)\n",
    "    j = 0\n",
    "    t1 = time()\n",
    "    for batch in dataloader:\n",
    "        u, m, r = batch\n",
    "        # move tensors to cuda\n",
    "        u = u.to(device)\n",
    "        m = m.to(device)\n",
    "        r = r.to(device)\n",
    "\n",
    "        y_hat = ncf(u.squeeze(1), m.squeeze(1))\n",
    "        loss = torch.nn.BCELoss()  # (weight=w, reduction=\"mean\")\n",
    "\n",
    "        loss = loss(y_hat, r.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if j % int(1 + it_per_epoch / 10) == 0:\n",
    "            print(f\"\\rProgress: {round(100 * j / it_per_epoch)}%\", end='')\n",
    "        j+=1\n",
    "\n",
    "    t2 = time()\n",
    "    print(\"Epoch time:\", round(t2 - t1), \"seconds\")\n",
    "    print(\"Loss:\", loss.cpu().detach().numpy().round(3))\n",
    "    ncf.eval()\n",
    "    hr, ndcg = eval_model(ncf, data, n_users, device)\n",
    "\n",
    "    print(f\"HR@{top_k}: {round(hr, 2)}  NDCG@{top_k}: {round(ndcg, 2)}\\n\")\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
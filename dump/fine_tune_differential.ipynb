{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" FINE TUNING MODEL WITH DIFFERENTIAL PRIVACY \"\"\"\n",
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import NCF\n",
    "from fairness_measures import Measures\n",
    "\n",
    "import data\n",
    "from importlib import reload\n",
    "reload(data)\n",
    "from data import AttributeData, TargetData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_k = 10\n",
    "\n",
    "learning_rate = .001\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% CONSTANTS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscocancedda/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/Users/franciscocancedda/Documents/Scool/NFPCF/venv/lib/python3.9/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "data = AttributeData()\n",
    "m = Measures()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD DATA AND FAIRNESS FUNCTIONS\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ncf = NCF(6040, 3952, emb_size, hidden_layers, output_size).to(device)\n",
    "ncf.load_state_dict(torch.load(\"models/preTrained_NCF\"))\n",
    "\n",
    "# FETCH NUMBER OF UNIQUE CAREERS\n",
    "n_careers = data.num_jobs\n",
    "\n",
    "# CHANGE EMBEDDING SIZE TO FIT SENSITIVE INFO\n",
    "ncf.like_emb = nn.Embedding(n_careers, emb_size).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD PRE-TRAINED MODEL\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine(\n",
    "    ncf,\n",
    "    sample_rate=0.01,\n",
    "    alphas=[10, 100],\n",
    "    noise_multiplier=1.3,\n",
    "    max_grad_norm=1.0,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_differential_privacy_model():\n",
    "    loss = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "    privacy_engine.attach(optimizer)\n",
    "    final_loss = 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        j = 0\n",
    "        dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0)\n",
    "        it_per_epoch = len(data) / batch_size\n",
    "\n",
    "        for batch in dataloader:\n",
    "            usr, jb, _, rt = batch\n",
    "            # LOAD BATCH\n",
    "            users = usr.to(device)\n",
    "            jobs = jb.to(device)  # career\n",
    "            ratings = rt.to(device)\n",
    "            # PREDICTIONS\n",
    "            y_hat = ncf(users.squeeze(1), jobs.squeeze(1))\n",
    "\n",
    "            # BINARY CROSS-ENTROPY LOSS\n",
    "            final_loss = loss(y_hat, ratings.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if j % int(1 + it_per_epoch / 10) == 0:\n",
    "                print(f\"Progress: {round(100 * j / it_per_epoch)}%\")\n",
    "            j += 1\n",
    "        ht, ndcg = evaluate_fine_tune(ncf, data.test, top_k, random_samples)\n",
    "        print(f'Hit Ratio: {ht}  NDCG: {ndcg}   LOSS1: {final_loss}')\n",
    "\n",
    "\n",
    "\n",
    "# features = ['age', 'gender', 'job']\n",
    "\n",
    "\n",
    "\n",
    "    # local_epsilon = 4\n",
    "\n",
    "    # job = get_dummies(data.train.job, drop_first=True)\n",
    "    # gender = get_dummies(data.train.gender, drop_first=True)\n",
    "    # age = 2 * ( (data.train.age - data.train.age.min()) / (data.train.age.max() - data.train.age.min()) ) - 1\n",
    "\n",
    "    # slack = np.max(1, n_features, np.int8(local_epsilon/2.5))\n",
    "    # job.apply(lambda x: np.float32(.5) if x==1 else 1/(np.exp(local_epsilon/slack) + 1))\n",
    "    # users_tensor = torch.LongTensor(data.train.uid.values).to(device)\n",
    "    # jobs_tensor = torch.LongTensor(job.values).to(device)\n",
    "    # genders_tensor = torch.LongTensor(gender.values).to(device)\n",
    "    # ages_tensor = torch.LongTensor(age.values).to(device)\n",
    "    #\n",
    "    # all_features =\n",
    "    # optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% TRAIN MODEL\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "def evaluate_fine_tune(model, df_val, k, random_samples):\n",
    "    model.eval()\n",
    "    avg_hr = np.zeros((len(df_val), k))\n",
    "    avg_ndcg = np.zeros((len(df_val), k))\n",
    "\n",
    "    for i in range(len(df_val)):\n",
    "        test_df = data.add_negatives(\n",
    "            df_val,\n",
    "            item='job',\n",
    "            items=data.jobs,\n",
    "            n_samples=random_samples\n",
    "        )\n",
    "        users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.job).to(device)\n",
    "        y_hat = model(users, items)\n",
    "\n",
    "        y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "        items = items.cpu().detach().numpy().reshape((-1,))\n",
    "        map_item_score = {}\n",
    "        for j in range(len(y_hat)):\n",
    "            map_item_score[items[j]] = y_hat[j]\n",
    "        for k in range(k):\n",
    "            # Evaluate top rank list\n",
    "            ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "            gtItem = items[0]\n",
    "            avg_hr[i, k] = m.get_hit_ratio(ranklist, gtItem)\n",
    "            avg_ndcg[i, k] = m.get_ndcg(ranklist, gtItem)\n",
    "        avg_hr = np.mean(avg_hr, axis=0)\n",
    "        avg_ndcg = np.mean(avg_ndcg, axis=0)\n",
    "        return avg_hr, avg_ndcg\n",
    "\n",
    "# SET MODEL TO TRAINING MODE\n",
    "ncf.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% DECLARE OPTIMIZER + EVALUATION FUNCTION\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# all_users = torch.LongTensor(train['uid'].values).to(device)\n",
    "# all_items = torch.LongTensor(train['job'].values).to(device)\n",
    "# all_genders = torch.LongTensor(train['gender'].values).to(device)\n",
    "# def train_differential(train_fraction):\n",
    "#     # REMOVES JOBS BASED ON THRESHOLD + SPLIT DATA\n",
    "#     train, test = data.train_test_split(train_fraction)\n",
    "#     # num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "#\n",
    "#     # ADAM OPTIMIZER\n",
    "#     optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "#\n",
    "#     for i in range(num_epochs):\n",
    "#         dataloader = DataLoader(data, batch_size=batch_size,\n",
    "#                                 shuffle=True, num_workers=0)\n",
    "#\n",
    "#         it_per_epoch = len(data) / batch_size\n",
    "#         loss1, loss2, j = 0, 0, 1\n",
    "#\n",
    "#         for batch in dataloader:\n",
    "#             u, c, g, r = batch\n",
    "#\n",
    "#             # LOAD BATCH\n",
    "#             users = u.to(device)\n",
    "#             jobs = c.to(device)  # career\n",
    "#             # genders = g.to(device)\n",
    "#             ratings = r.to(device)\n",
    "#\n",
    "#             # PREDICTIONS\n",
    "#             y_hat = ncf(users, jobs)\n",
    "#\n",
    "#             noise = np.random.laplace(delta/n_inputs)\n",
    "#             # BINARY CROSS-ENTROPY LOSS\n",
    "#             loss = nn.BCELoss(y_hat + np.random.laplace(), ratings.unsqueeze(1)) + noise\n",
    "#\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#\n",
    "#             if j % int(1 + it_per_epoch / 10) == 0:\n",
    "#                 print(f\"Progress: {round(100 * j / it_per_epoch)}%\")\n",
    "#             j += 1\n",
    "#         ht, ndcg = evaluate_fine_tune(ncf, test, top_k, random_samples)\n",
    "#         print(f'Hit Ratio: {ht}  NDCG: {ndcg}   LOSS1: {loss1}  LOSS2: {loss2} ')\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "train_differential_privacy_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% LOAD TRAINING DATA\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Function for evaluating PRIVACY ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(ncf.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- SAVE ---\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import utils\n",
    "from data import FairnessData\n",
    "from torch.utils.data import DataLoader\n",
    "from data import DataGenerator\n",
    "from models import NCF\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing data...\")\n",
    "data = DataGenerator()\n",
    "print(\"Done\")\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- PARSING DATA ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- LOAD DATA ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "'''TRAIN MODEL ( MINI BATCH )'''\n",
    "def evaluate_model(model, df_val:pd.DataFrame, top_K, random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val), top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val), top_K))\n",
    "    test_df = data.add_negatives(\n",
    "        df_val,\n",
    "        n_samples=random_samples\n",
    "    )\n",
    "    gp = test_df.groupby('uid')\n",
    "    for i, g in gp:\n",
    "        for k in range(top_K):\n",
    "            users, items = torch.LongTensor(g.uid.to_numpy()).to(device), torch.LongTensor(g.mid.to_numpy()).to(device)\n",
    "            y_hat = model(users, items)\n",
    "            y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "            test_item_input = items.cpu().detach().numpy().reshape((-1,))\n",
    "            map_item_score = dict(zip(test_item_input, y_hat))\n",
    "            ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "            gtItem = test_item_input[0]\n",
    "            for item in ranklist:\n",
    "                if item==gtItem:\n",
    "                    avg_HR[i, k] = 1\n",
    "                    avg_NDCG[i, k] = math.log(2) / math.log(i+2)\n",
    "                else:\n",
    "                    avg_HR[i, k] = 0\n",
    "                    avg_NDCG[i, k] = 0\n",
    "    avg_HR = np.mean(avg_HR, axis=0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis=0)\n",
    "    return avg_HR, avg_NDCG\n",
    "\n",
    "def evaluate(model, df_val:pd.DataFrame, k=10):\n",
    "    test_df = data.add_negatives(df_val, n_samples=random_samples)\n",
    "    users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.mid).to(device)\n",
    "    y_hat = model(users, items)\n",
    "    test_df['score'] = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "    grouped = test_df.copy(deep=True)\n",
    "    grouped['rank'] = grouped.groupby('uid')['score'].rank(method='first', ascending=False)\n",
    "    grouped.sort_values(['uid', 'rank'], inplace=True)\n",
    "    test_in_top_k = grouped[(grouped['rank']<=k) & (grouped['rating'] == 1)]\n",
    "    # test_in_top_k = top_k[top_k['rating'] == 1]\n",
    "    hr = test_in_top_k.shape[0] / data.num_users\n",
    "    test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(lambda x: np.log(2)/np.log(1 + x))\n",
    "    ndcg = test_in_top_k.ndcg.sum() / data.num_users\n",
    "    return hr, ndcg\n",
    "\n",
    "def rank(l, item):\n",
    "    # rank of the test item in the list of negative instances\n",
    "    # returns the number of elements that the test item is bigger than\n",
    "\n",
    "    index = 0\n",
    "    for element in l:\n",
    "        if element > item:\n",
    "            index += 1\n",
    "            return index\n",
    "        index += 1\n",
    "    return index\n",
    "\n",
    "def eval_model(model, data, num_users=6040):\n",
    "    # Evaluates the model and returns HR@10 and NDCG@10\n",
    "    user_test, item_test = evaluator.get_test_tensor(data.test)\n",
    "\n",
    "    hits = 0\n",
    "    ndcg = 0\n",
    "    for i in range(num_users):\n",
    "        user = user_test[i:i+100]\n",
    "        item = item_test[i:i+100]\n",
    "        y = model(user, item)\n",
    "        y = y.tolist()\n",
    "        y = sum(y, [])\n",
    "        first = y.pop(0)\n",
    "\n",
    "        y.sort()\n",
    "\n",
    "        ranking = rank(y, first)\n",
    "\n",
    "        if ranking > 90:\n",
    "            hits += 1\n",
    "            ndcg += np.log(2) / np.log(len(user_test) - ranking + 1)\n",
    "\n",
    "    hr = hits / data.num_users\n",
    "    ndcg = ndcg / data.num_users\n",
    "    return hr, ndcg\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Functions for evaluation ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_12426/4023685616.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "t = data.training_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Hyper parameters ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "    uid   mid  rating\n0     0     0       1\n1     0     1       1\n2     0     2       1\n3     0     3       1\n4     0     4       1\n5     0     5       1\n6     0     6       1\n7     0     7       1\n8     0     8       1\n9     0     9       1\n10    0    10       1\n11    0    11       1\n12    0    12       1\n13    0    13       1\n14    0    14       1\n15    0    15       1\n16    0    16       1\n17    0    17       1\n18    0    18       1\n19    0    19       1\n20    0    20       1\n21    0    21       1\n22    0    22       1\n23    0    23       1\n24    0    24       1\n25    0    26       1\n26    0    27       1\n27    0    28       1\n28    0    29       1\n29    0    30       1\n30    0    31       1\n31    0    32       1\n32    0    33       1\n33    0    34       1\n34    0    35       1\n35    0    36       1\n36    0    37       1\n37    0    38       1\n38    0    39       1\n39    0    40       1\n40    0    41       1\n41    0    42       1\n42    0    43       1\n43    0    44       1\n44    0    45       1\n45    0    46       1\n46    0    47       1\n47    0    48       1\n48    0    49       1\n49    0    50       1\n50    0    51       1\n51    0    52       1\n52    0   422       0\n53    0   868       0\n54    0  1165       0\n55    0  3024       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>15</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>20</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>21</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0</td>\n      <td>22</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0</td>\n      <td>23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>24</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0</td>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0</td>\n      <td>27</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0</td>\n      <td>28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>29</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0</td>\n      <td>30</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0</td>\n      <td>31</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0</td>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0</td>\n      <td>35</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0</td>\n      <td>36</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0</td>\n      <td>37</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0</td>\n      <td>39</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0</td>\n      <td>41</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0</td>\n      <td>42</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0</td>\n      <td>44</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0</td>\n      <td>46</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0</td>\n      <td>48</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0</td>\n      <td>49</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0</td>\n      <td>51</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0</td>\n      <td>422</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0</td>\n      <td>868</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>0</td>\n      <td>1165</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>0</td>\n      <td>3024</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[t.uid==0]\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Hyper parameters ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "learning_rate = .001\n",
    "\n",
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "random_samples = 100\n",
    "num_negatives = 4\n",
    "top_K = 10\n",
    "\n",
    "C = 0.4  # pop sample ratio\n",
    "eta = 80  # federated param\n",
    "E = 1  # epochs\n",
    "# B = 102  # batch size\n",
    "T = 196  # num rounds\n",
    "# lr = 0.3  # learning rate\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Hyper parameters ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.test.head()\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_ncf(model, evaluator):\n",
    "    # data.get_train_instances(seed=e)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),  lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "    t1 = time()\n",
    "\n",
    "    it_per_epoch = len(data) / batch_size\n",
    "    for i in range(num_epochs):\n",
    "        ncf.train()\n",
    "        print(\"Starting epoch \", i + 1)\n",
    "        j = 0\n",
    "        for batch in dataloader:\n",
    "            u, m, r = batch\n",
    "            # move tensors to cuda\n",
    "            u = u.to(device)\n",
    "            m = m.to(device)\n",
    "            r = r.to(device)\n",
    "\n",
    "            y_hat = model(u.squeeze(1), m.squeeze(1))\n",
    "\n",
    "            loss = torch.nn.BCELoss()  # (weight=w, reduction=\"mean\")\n",
    "            loss = loss(y_hat, r.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if j % int(1 + it_per_epoch / 10) == 0:\n",
    "                print(\"Progress: \", round(100 * j / it_per_epoch), \"%\")\n",
    "            j+=1\n",
    "\n",
    "        # Epoch metrics\n",
    "        t2 = time()\n",
    "        print(\"Epoch time:\", round(t2 - t1), \"seconds\")\n",
    "        print(\"Loss:\", loss / i)\n",
    "\n",
    "        print(\"Evaluating model...\")\n",
    "        ncf.eval()\n",
    "        t1 = time()\n",
    "        hr, ndcg = evaluator()\n",
    "        # hr, ndcg = evaluate(model, data.test, top_K)\n",
    "        t2 = time()\n",
    "        print(\"Evaluation time:\", round(t2 - t1), \"seconds\")\n",
    "        print(f\"HR@{top_k}:{hr}\")\n",
    "        print(f\"NDCG@{top_k}:{ndcg}\")\n",
    "\n",
    "        print(\"Evaluating (fed)...\")\n",
    "        t1 = time()\n",
    "        hr, ndcg = eval_model(model, data)\n",
    "        t2 = time()\n",
    "        print(\"Evaluation time:\", round(t2 - t1), \"seconds\")\n",
    "        print(f\"HR@{top_k}:{hr}\")\n",
    "        print(f\"NDCG@{top_k}:{ndcg}\")\n",
    "        # new\n",
    "        # HR, NDCG = evaluate_model(model, data, validation=False)\n",
    "        # updated\n",
    "        # hr, ndcg = evaluate_model(model, data.test, top_K, random_samples)\n",
    "        # original\n",
    "        loss = 0\n",
    "        print()\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "def fed_fit(model_central, data, C, batch_size, epochs, lr, eta, verbose=True):\n",
    "\n",
    "    # Sample the participants for the round of training\n",
    "    num_participants = int(data.num_users * C)\n",
    "    participants = random.sample(range(data.num_users), num_participants)\n",
    "\n",
    "    # model_difference holds the total change of the global model after the round\n",
    "    model_difference = copy.deepcopy(model_central)\n",
    "    utils.zero_model_parameters(model_difference)\n",
    "\n",
    "    it = 0\n",
    "\n",
    "    t1 = time()\n",
    "\n",
    "    # Start training loop\n",
    "    for user in participants:\n",
    "\n",
    "        it += 1\n",
    "        if it % int(num_participants / 10) == 0 and verbose:\n",
    "            print(\"Progress:\", round(100 * it / num_participants), \"%\")\n",
    "\n",
    "        # The current user takes a copy of the global model\n",
    "        model_client = copy.deepcopy(model_central)\n",
    "\n",
    "        # Defining optimizers\n",
    "        optimizer = torch.optim.SGD(model_client.parameters(), lr=lr)  # MLP optimizer\n",
    "        optimizer_u = torch.optim.SGD(model_client.user_embedding.parameters(), lr=lr / C * eta - lr)  # User optimizer\n",
    "        optimizer_i = torch.optim.SGD(model_client.item_embedding.parameters(),\n",
    "                                      lr=lr * data.num_items * eta - lr)  # Item optimizer\n",
    "\n",
    "        # Prepares data for the current user\n",
    "        # data.set_current_user(user)\n",
    "        # data.generate_negatives()\n",
    "\n",
    "        dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                                shuffle=True, num_workers=0)\n",
    "\n",
    "        # Trains on the users data\n",
    "        for e in range(epochs):\n",
    "            for batch in dataloader:\n",
    "                # Load tensors of users, movies, outputs and loss weights\n",
    "                u, m, y = batch\n",
    "                # move tensors to cuda\n",
    "                u = u.to(device)\n",
    "                m = m.to(device)\n",
    "                y = y.to(device)\n",
    "                # w = w.to(device)\n",
    "\n",
    "                # make predictions\n",
    "                p_pred = model_client(u, m)\n",
    "\n",
    "                # Calculate mean loss\n",
    "                loss_fn = torch.nn.BCELoss()  # weight=w, reduction=\"mean\")\n",
    "                loss = loss_fn(p_pred, y)\n",
    "\n",
    "                # Backpropagate the output and update model parameters\n",
    "                optimizer.zero_grad()\n",
    "                optimizer_u.zero_grad()\n",
    "                optimizer_i.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer_u.step()\n",
    "                optimizer_i.step()\n",
    "\n",
    "        # Calculate the user's change of the model and add it to the total change\n",
    "        utils.sub_model_parameters(model_central, model_client)\n",
    "        utils.add_model_parameters(model_client, model_difference)\n",
    "\n",
    "    # Take the average of the MLP and item vectors\n",
    "    utils.divide_model_parameters(model_difference, num_participants)\n",
    "\n",
    "    # Update the global model by adding the total change\n",
    "    utils.add_model_parameters(model_difference, model_central)\n",
    "    t2 = time.time()\n",
    "    print(\"Time of round:\", round(t2 - t1), \"seconds\")\n",
    "\n",
    "def train_fed():\n",
    "    for t in range(T):  # for each round\n",
    "        print(\"Starting round\", t + 1)\n",
    "        # train one round\n",
    "        fed_fit(model_central, data, C=C, batch_size=batch_size, epochs=E, lr=learning_rate, eta=eta, verbose=True)\n",
    "        print(\"Evaluating model...\")\n",
    "        # HR, NDCG = evaluate_model(model_central, data, validation=False)\n",
    "        # hr, ndcg = evaluate_model(\n",
    "        #     NCF,\n",
    "        #     data.test.values,\n",
    "        #     25,\n",
    "        #     random_samples,\n",
    "        #     data.num_movies\n",
    "        # )\n",
    "        print(\"HR@10:\", hr)\n",
    "        print(\"NDCG@10\", ndcg)\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Functions for training ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ncf = NCF(data.num_users, data.num_movies, emb_size, hidden_layers, output_size).to(device)\n",
    "ncf\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- TRAIN MODEL ( MINI BATCH ) ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evaluate import Evaluate\n",
    "evaluator = Evaluate(ncf, data, device=device)\n",
    "\n",
    "train_ncf(ncf, evaluator)\n",
    "torch.save(ncf.state_dict(), \"models/preTrained_NCF\")\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initiate model\n",
    "model_central = NCF(\n",
    "    num_users=data.num_users,\n",
    "    num_items=data.num_movies,\n",
    "    embed_size=emb_size,\n",
    "    num_hidden=hidden_layers,\n",
    "    output_size=output_size\n",
    ")\n",
    "\n",
    "torch.save(model_central.state_dict(), \"models/federatedNCF\")\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Train FedFit model  ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' GET USER EMBEDDING '''\n",
    "\n",
    "sensitive = FairnessData()\n",
    "clean = sensitive.df\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "train, test = sensitive.train_test_split(train_ratio)\n",
    "\n",
    "\n",
    "clean.info()  # 1476+3444 = 4920"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- GET USER EMBEDDING ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% -----------------------------------------------------------------\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_embeds = ncf.user_emb.weight.data.cpu().detach().numpy()\n",
    "user_embeds = user_embeds.astype('float')\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' COMPUTE GENDER EMBEDDING '''\n",
    "gender_embed = np.zeros((2,user_embeds.shape[1]))\n",
    "num_users_x_group = np.zeros((2, 1))\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    u = train['uid'].iloc[i]\n",
    "    if train['gender'].iloc[i] == 0:\n",
    "        gender_embed[0] +=  user_embeds[u]\n",
    "        num_users_x_group[0] += 1.0\n",
    "    else:\n",
    "        gender_embed[1] +=  user_embeds[u]\n",
    "        gender_embed[1] += 1.0\n",
    "        num_users_x_group[1] += 1.0\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- COMPUTE GENDER EMBEDDING ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' VERTICAL BIAS'''\n",
    "gender_embed = gender_embed / num_users_x_group\n",
    "# vBias = compute_bias_direction(gender_embed)\n",
    "vBias = gender_embed[1].reshape((1,-1)) - gender_embed[0].reshape((1,-1))\n",
    "vBias = vBias / np.linalg.norm(vBias,axis=1,keepdims=1)\n",
    "\n",
    "vBias\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- VERTICAL BIAS ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "''' LINEAR PROJECTION '''\n",
    "\n",
    "# debias users\n",
    "debiased_user_embeds = user_embeds\n",
    "for i in range(len(clean)):\n",
    "    u = clean['uid'].iloc[i]\n",
    "    debiased_user_embeds[u] = user_embeds[u] - (np.inner(user_embeds[u].reshape(1,-1),vBias)[0][0])*vBias\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- LINEAAR PROJECTION ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''UPDATE USER EMBEDDINGS'''\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n",
    "\n",
    "n_careers = sensitive.num_jobs\n",
    "\n",
    "# replace page items with career items\n",
    "ncf.like_emb = nn.Embedding(n_careers,emb_size).to(device)\n",
    "# freeze user embedding\n",
    "ncf.user_emb.weight.requires_grad=False\n",
    "\n",
    "# replace user embedding of the model with debiased embeddings\n",
    "ncf.user_emb.weight.data = torch.from_numpy(debiased_user_embeds.astype(np.float32)).to(device)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Fine Tune for career optimization ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''OPTIMIZE'''\n",
    "# fair_fine_tune_model(DF_NCF,train_data, num_epochs, learning_rate,batch_size,num_negatives,n_careers,train_gender,fairness_thres,epsilonBase, unsqueeze=True)\n",
    "emb_size = 128\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_k = 10\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(ncf.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "ncf.train()\n",
    "\n",
    "torch.save(ncf.state_dict(), \"models/DF_NCF\")\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- OPTIMIZE ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''FAIR FINE TUNING MODEL'''\n",
    "all_users = torch.LongTensor(train['uid'].values).to(device)\n",
    "all_items = torch.LongTensor(train['job'].values).to(device)\n",
    "# protected attribute\n",
    "all_genders = torch.LongTensor(train['gender'].values).to(device)\n",
    "\n",
    "from fairness_measures import Measures\n",
    "m = Measures()\n",
    "\n",
    "num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    dataloader = DataLoader(sensitive, batch_size=batch_size,\n",
    "                            shuffle=True, num_workers=0)\n",
    "    t1 = time.time()\n",
    "\n",
    "    it_per_epoch = len(data) / batch_size\n",
    "    j = 1\n",
    "    for batch in dataloader:\n",
    "        u, j, g, r = batch\n",
    "        # move tensors to cuda\n",
    "        users = u.to(device)\n",
    "        jobs = m.to(device)\n",
    "        genders = g.to(device)\n",
    "        ratings = r.to(device)\n",
    "        \n",
    "        # users = torch.LongTensor(batch_df.uid.to_numpy()).to(device)\n",
    "        # items = torch.LongTensor(batch_df.job.to_numpy()).to(device)\n",
    "        # ratings = torch.FloatTensor(batch_df.rating.to_numpy()).to(device)\n",
    "        # print(items)\n",
    "        y_hat = ncf(users, jobs)\n",
    "\n",
    "        loss1 = nn.BCELoss(y_hat, ratings.unsqueeze(1))\n",
    "\n",
    "        predicted_probs = ncf(all_users, all_items)\n",
    "        avg_epsilon = m.computeEDF(all_genders,predicted_probs,n_careers,all_items,device)\n",
    "        print(avg_epsilon)\n",
    "        #criteroin hinge\n",
    "        loss2 = torch.max(torch.tensor(0.0).to(device), (avg_epsilon-epsilonBase))\n",
    "\n",
    "        loss = loss1 + fairness_thres*loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'epoch: {i + 1} \\nbatch: {j} out of: {num_batches} \\naverage loss: {loss.item()}\\n')\n",
    "        j+=1\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- FINE TUNING ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(ncf.state_dict(), \"models/DF_NCF\")\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- SAVE ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "def evaluate_fine_tune(model,df_val,top_K,random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val),top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val),top_K))\n",
    "\n",
    "    # for i in range(len(df_val)):\n",
    "    test_df = sensitive.add_negatives(\n",
    "        df_val,\n",
    "        item='job',\n",
    "        items=sensitive.jobs,\n",
    "        n_samples=random_samples\n",
    "    )\n",
    "    users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.job).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "    items = items.cpu().detach().numpy().reshape((-1,))\n",
    "    map_item_score = {}\n",
    "    for j in range(len(y_hat)):\n",
    "        map_item_score[items[j]] = y_hat[j]\n",
    "    for k in range(top_K):\n",
    "        # Evaluate top rank list\n",
    "        ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "        gtItem = items[0]\n",
    "        avg_HR[i,k] = getHitRatio(ranklist, gtItem)\n",
    "        avg_NDCG[i,k] = getNDCG(ranklist, gtItem)\n",
    "    avg_HR = np.mean(avg_HR, axis = 0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis = 0)\n",
    "    return avg_HR, avg_NDCG\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Functions for evaluating model ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''EVALUATE TUNED MODEL'''\n",
    "hr, ndcg = evaluate_fine_tune(ncf, test, top_K, random_samples)\n",
    "\n",
    "hr\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Evaluate Model ---\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''MEASURE THE FAIRNESS OF THE MODEL'''\n",
    "def fairness_measures(model,df_val,num_items):\n",
    "    model.eval()\n",
    "    users, items = torch.LongTensor(df_val.uid.to_numpy()).to(device), torch.LongTensor(df_val.job.to_numpy()).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    avg_epsilon = m.computeEDF(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "    U_abs = m.compute_absolute_unfairness(all_genders.cpu(),y_hat,num_items,items,device)\n",
    "\n",
    "    avg_epsilon = avg_epsilon.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"average differential fairness: {avg_epsilon: .3f}\")\n",
    "\n",
    "    U_abs = U_abs.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"absolute unfairness: {U_abs: .3f}\")\n",
    "\n",
    "fairness_measures(ncf, test, n_careers)\n",
    "\n",
    "# -----------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% --- Function for evaluating fairness ---\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
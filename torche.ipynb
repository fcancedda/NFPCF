{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from data import DataGenerator\n",
    "\n",
    "data = DataGenerator()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = data.train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "          uid   mid  rating\n0           0  1192       1\n1           0   660       1\n2           0   913       1\n3           0  3407       1\n4           0  2354       1\n...       ...   ...     ...\n1000204  6039  1090       1\n1000205  6039  1093       1\n1000206  6039   561       1\n1000207  6039  1095       1\n1000208  6039  1096       1\n\n[994169 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1192</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>660</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>913</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3407</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2354</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1000204</th>\n      <td>6039</td>\n      <td>1090</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1000205</th>\n      <td>6039</td>\n      <td>1093</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1000206</th>\n      <td>6039</td>\n      <td>561</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1000207</th>\n      <td>6039</td>\n      <td>1095</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1000208</th>\n      <td>6039</td>\n      <td>1096</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>994169 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_likes, embed_size, num_hidden, output_size):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embed_size)\n",
    "        self.like_emb = nn.Embedding(num_likes,embed_size)\n",
    "        self.fc1 = nn.Linear(embed_size*2, num_hidden[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(num_hidden[0], num_hidden[1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(num_hidden[1], num_hidden[2])\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(num_hidden[2], num_hidden[3])\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.outLayer = nn.Linear(num_hidden[3], output_size)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.like_emb(v)\n",
    "        out = torch.cat([U,V], dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.outLayer(out)\n",
    "        out = self.out_act(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "num_epochs = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 2048\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 100\n",
    "top_K = 10\n",
    "\n",
    "preTrained_NCF = NCF(data.num_users, data.num_movies, emb_size, hidden_layers, output_size).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "NCF(\n  (user_emb): Embedding(6040, 128)\n  (like_emb): Embedding(3952, 128)\n  (fc1): Linear(in_features=256, out_features=128, bias=True)\n  (relu1): ReLU()\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (relu2): ReLU()\n  (fc3): Linear(in_features=64, out_features=32, bias=True)\n  (relu3): ReLU()\n  (fc4): Linear(in_features=32, out_features=16, bias=True)\n  (relu4): ReLU()\n  (outLayer): Linear(in_features=16, out_features=1, bias=True)\n  (out_act): Sigmoid()\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(preTrained_NCF.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "preTrained_NCF.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \n",
      "batch: 0 out of: 485 \n",
      "average loss: 0.6260589361190796\n",
      "\n",
      "epoch: 1 \n",
      "batch: 1 out of: 485 \n",
      "average loss: 0.6183147430419922\n",
      "\n",
      "epoch: 1 \n",
      "batch: 2 out of: 485 \n",
      "average loss: 0.6109557151794434\n",
      "\n",
      "epoch: 1 \n",
      "batch: 3 out of: 485 \n",
      "average loss: 0.6005444526672363\n",
      "\n",
      "epoch: 1 \n",
      "batch: 4 out of: 485 \n",
      "average loss: 0.5967397689819336\n",
      "\n",
      "epoch: 1 \n",
      "batch: 5 out of: 485 \n",
      "average loss: 0.5918882489204407\n",
      "\n",
      "epoch: 1 \n",
      "batch: 6 out of: 485 \n",
      "average loss: 0.5858030915260315\n",
      "\n",
      "epoch: 1 \n",
      "batch: 7 out of: 485 \n",
      "average loss: 0.5710885524749756\n",
      "\n",
      "epoch: 1 \n",
      "batch: 8 out of: 485 \n",
      "average loss: 0.5681321024894714\n",
      "\n",
      "epoch: 1 \n",
      "batch: 9 out of: 485 \n",
      "average loss: 0.553505539894104\n",
      "\n",
      "epoch: 1 \n",
      "batch: 10 out of: 485 \n",
      "average loss: 0.5428939461708069\n",
      "\n",
      "epoch: 1 \n",
      "batch: 11 out of: 485 \n",
      "average loss: 0.531600832939148\n",
      "\n",
      "epoch: 1 \n",
      "batch: 12 out of: 485 \n",
      "average loss: 0.5277777314186096\n",
      "\n",
      "epoch: 1 \n",
      "batch: 13 out of: 485 \n",
      "average loss: 0.5100416541099548\n",
      "\n",
      "epoch: 1 \n",
      "batch: 14 out of: 485 \n",
      "average loss: 0.4909614324569702\n",
      "\n",
      "epoch: 1 \n",
      "batch: 15 out of: 485 \n",
      "average loss: 0.4838981628417969\n",
      "\n",
      "epoch: 1 \n",
      "batch: 16 out of: 485 \n",
      "average loss: 0.45197081565856934\n",
      "\n",
      "epoch: 1 \n",
      "batch: 17 out of: 485 \n",
      "average loss: 0.4463226795196533\n",
      "\n",
      "epoch: 1 \n",
      "batch: 18 out of: 485 \n",
      "average loss: 0.43185731768608093\n",
      "\n",
      "epoch: 1 \n",
      "batch: 19 out of: 485 \n",
      "average loss: 0.40277883410453796\n",
      "\n",
      "epoch: 1 \n",
      "batch: 20 out of: 485 \n",
      "average loss: 0.3839637339115143\n",
      "\n",
      "epoch: 1 \n",
      "batch: 21 out of: 485 \n",
      "average loss: 0.36084064841270447\n",
      "\n",
      "epoch: 1 \n",
      "batch: 22 out of: 485 \n",
      "average loss: 0.3419753909111023\n",
      "\n",
      "epoch: 1 \n",
      "batch: 23 out of: 485 \n",
      "average loss: 0.2988053560256958\n",
      "\n",
      "epoch: 1 \n",
      "batch: 24 out of: 485 \n",
      "average loss: 0.2729562819004059\n",
      "\n",
      "epoch: 1 \n",
      "batch: 25 out of: 485 \n",
      "average loss: 0.2585156559944153\n",
      "\n",
      "epoch: 1 \n",
      "batch: 26 out of: 485 \n",
      "average loss: 0.24116849899291992\n",
      "\n",
      "epoch: 1 \n",
      "batch: 27 out of: 485 \n",
      "average loss: 0.25287094712257385\n",
      "\n",
      "epoch: 1 \n",
      "batch: 28 out of: 485 \n",
      "average loss: 0.21265515685081482\n",
      "\n",
      "epoch: 1 \n",
      "batch: 29 out of: 485 \n",
      "average loss: 0.16116933524608612\n",
      "\n",
      "epoch: 1 \n",
      "batch: 30 out of: 485 \n",
      "average loss: 0.1513398438692093\n",
      "\n",
      "epoch: 1 \n",
      "batch: 31 out of: 485 \n",
      "average loss: 0.1586107611656189\n",
      "\n",
      "epoch: 1 \n",
      "batch: 32 out of: 485 \n",
      "average loss: 0.13728012144565582\n",
      "\n",
      "epoch: 1 \n",
      "batch: 33 out of: 485 \n",
      "average loss: 0.14889730513095856\n",
      "\n",
      "epoch: 1 \n",
      "batch: 34 out of: 485 \n",
      "average loss: 0.10522126406431198\n",
      "\n",
      "epoch: 1 \n",
      "batch: 35 out of: 485 \n",
      "average loss: 0.18439358472824097\n",
      "\n",
      "epoch: 1 \n",
      "batch: 36 out of: 485 \n",
      "average loss: 0.10686062276363373\n",
      "\n",
      "epoch: 1 \n",
      "batch: 37 out of: 485 \n",
      "average loss: 0.09667552262544632\n",
      "\n",
      "epoch: 1 \n",
      "batch: 38 out of: 485 \n",
      "average loss: 0.06062367558479309\n",
      "\n",
      "epoch: 1 \n",
      "batch: 39 out of: 485 \n",
      "average loss: 0.12945052981376648\n",
      "\n",
      "epoch: 1 \n",
      "batch: 40 out of: 485 \n",
      "average loss: 0.033779025077819824\n",
      "\n",
      "epoch: 1 \n",
      "batch: 41 out of: 485 \n",
      "average loss: 0.1347474902868271\n",
      "\n",
      "epoch: 1 \n",
      "batch: 42 out of: 485 \n",
      "average loss: 0.17484761774539948\n",
      "\n",
      "epoch: 1 \n",
      "batch: 43 out of: 485 \n",
      "average loss: 0.12105602771043777\n",
      "\n",
      "epoch: 1 \n",
      "batch: 44 out of: 485 \n",
      "average loss: 0.16882525384426117\n",
      "\n",
      "epoch: 1 \n",
      "batch: 45 out of: 485 \n",
      "average loss: 0.1299603283405304\n",
      "\n",
      "epoch: 1 \n",
      "batch: 46 out of: 485 \n",
      "average loss: 0.11798229068517685\n",
      "\n",
      "epoch: 1 \n",
      "batch: 47 out of: 485 \n",
      "average loss: 0.07973451167345047\n",
      "\n",
      "epoch: 1 \n",
      "batch: 48 out of: 485 \n",
      "average loss: 0.11099027097225189\n",
      "\n",
      "epoch: 1 \n",
      "batch: 49 out of: 485 \n",
      "average loss: 0.092415951192379\n",
      "\n",
      "epoch: 1 \n",
      "batch: 50 out of: 485 \n",
      "average loss: 0.09090051800012589\n",
      "\n",
      "epoch: 1 \n",
      "batch: 51 out of: 485 \n",
      "average loss: 0.07735428959131241\n",
      "\n",
      "epoch: 1 \n",
      "batch: 52 out of: 485 \n",
      "average loss: 0.06566432863473892\n",
      "\n",
      "epoch: 1 \n",
      "batch: 53 out of: 485 \n",
      "average loss: 0.08377974480390549\n",
      "\n",
      "epoch: 1 \n",
      "batch: 54 out of: 485 \n",
      "average loss: 0.0719829797744751\n",
      "\n",
      "epoch: 1 \n",
      "batch: 55 out of: 485 \n",
      "average loss: 0.0968686044216156\n",
      "\n",
      "epoch: 1 \n",
      "batch: 56 out of: 485 \n",
      "average loss: 0.05733995512127876\n",
      "\n",
      "epoch: 1 \n",
      "batch: 57 out of: 485 \n",
      "average loss: 0.09247779101133347\n",
      "\n",
      "epoch: 1 \n",
      "batch: 58 out of: 485 \n",
      "average loss: 0.0922778770327568\n",
      "\n",
      "epoch: 1 \n",
      "batch: 59 out of: 485 \n",
      "average loss: 0.10149063169956207\n",
      "\n",
      "epoch: 1 \n",
      "batch: 60 out of: 485 \n",
      "average loss: 0.08077222108840942\n",
      "\n",
      "epoch: 1 \n",
      "batch: 61 out of: 485 \n",
      "average loss: 0.08939418941736221\n",
      "\n",
      "epoch: 1 \n",
      "batch: 62 out of: 485 \n",
      "average loss: 0.09209635108709335\n",
      "\n",
      "epoch: 1 \n",
      "batch: 63 out of: 485 \n",
      "average loss: 0.08446221053600311\n",
      "\n",
      "epoch: 1 \n",
      "batch: 64 out of: 485 \n",
      "average loss: 0.0856090635061264\n",
      "\n",
      "epoch: 1 \n",
      "batch: 65 out of: 485 \n",
      "average loss: 0.06951133161783218\n",
      "\n",
      "epoch: 1 \n",
      "batch: 66 out of: 485 \n",
      "average loss: 0.056728851050138474\n",
      "\n",
      "epoch: 1 \n",
      "batch: 67 out of: 485 \n",
      "average loss: 0.06583856791257858\n",
      "\n",
      "epoch: 1 \n",
      "batch: 68 out of: 485 \n",
      "average loss: 0.12361077964305878\n",
      "\n",
      "epoch: 1 \n",
      "batch: 69 out of: 485 \n",
      "average loss: 0.06577286124229431\n",
      "\n",
      "epoch: 1 \n",
      "batch: 70 out of: 485 \n",
      "average loss: 0.0695314109325409\n",
      "\n",
      "epoch: 1 \n",
      "batch: 71 out of: 485 \n",
      "average loss: 0.05984216183423996\n",
      "\n",
      "epoch: 1 \n",
      "batch: 72 out of: 485 \n",
      "average loss: 0.06847512722015381\n",
      "\n",
      "epoch: 1 \n",
      "batch: 73 out of: 485 \n",
      "average loss: 0.06297088414430618\n",
      "\n",
      "epoch: 1 \n",
      "batch: 74 out of: 485 \n",
      "average loss: 0.08398058265447617\n",
      "\n",
      "epoch: 1 \n",
      "batch: 75 out of: 485 \n",
      "average loss: 0.07074106484651566\n",
      "\n",
      "epoch: 1 \n",
      "batch: 76 out of: 485 \n",
      "average loss: 0.027604030445218086\n",
      "\n",
      "epoch: 1 \n",
      "batch: 77 out of: 485 \n",
      "average loss: 0.04942016676068306\n",
      "\n",
      "epoch: 1 \n",
      "batch: 78 out of: 485 \n",
      "average loss: 0.0991138443350792\n",
      "\n",
      "epoch: 1 \n",
      "batch: 79 out of: 485 \n",
      "average loss: 0.05994012579321861\n",
      "\n",
      "epoch: 1 \n",
      "batch: 80 out of: 485 \n",
      "average loss: 0.05847129970788956\n",
      "\n",
      "epoch: 1 \n",
      "batch: 81 out of: 485 \n",
      "average loss: 0.05372146889567375\n",
      "\n",
      "epoch: 1 \n",
      "batch: 82 out of: 485 \n",
      "average loss: 0.07204121351242065\n",
      "\n",
      "epoch: 1 \n",
      "batch: 83 out of: 485 \n",
      "average loss: 0.04848334565758705\n",
      "\n",
      "epoch: 1 \n",
      "batch: 84 out of: 485 \n",
      "average loss: 0.051840029656887054\n",
      "\n",
      "epoch: 1 \n",
      "batch: 85 out of: 485 \n",
      "average loss: 0.03034822642803192\n",
      "\n",
      "epoch: 1 \n",
      "batch: 86 out of: 485 \n",
      "average loss: 0.033313360065221786\n",
      "\n",
      "epoch: 1 \n",
      "batch: 87 out of: 485 \n",
      "average loss: 0.036728598177433014\n",
      "\n",
      "epoch: 1 \n",
      "batch: 88 out of: 485 \n",
      "average loss: 0.0653972178697586\n",
      "\n",
      "epoch: 1 \n",
      "batch: 89 out of: 485 \n",
      "average loss: 0.033991873264312744\n",
      "\n",
      "epoch: 1 \n",
      "batch: 90 out of: 485 \n",
      "average loss: 0.053911879658699036\n",
      "\n",
      "epoch: 1 \n",
      "batch: 91 out of: 485 \n",
      "average loss: 0.05509992316365242\n",
      "\n",
      "epoch: 1 \n",
      "batch: 92 out of: 485 \n",
      "average loss: 0.038027722388505936\n",
      "\n",
      "epoch: 1 \n",
      "batch: 93 out of: 485 \n",
      "average loss: 0.04787179082632065\n",
      "\n",
      "epoch: 1 \n",
      "batch: 94 out of: 485 \n",
      "average loss: 0.03764525428414345\n",
      "\n",
      "epoch: 1 \n",
      "batch: 95 out of: 485 \n",
      "average loss: 0.048635028302669525\n",
      "\n",
      "epoch: 1 \n",
      "batch: 96 out of: 485 \n",
      "average loss: 0.047139838337898254\n",
      "\n",
      "epoch: 1 \n",
      "batch: 97 out of: 485 \n",
      "average loss: 0.056833501905202866\n",
      "\n",
      "epoch: 1 \n",
      "batch: 98 out of: 485 \n",
      "average loss: 0.0534326508641243\n",
      "\n",
      "epoch: 1 \n",
      "batch: 99 out of: 485 \n",
      "average loss: 0.03021673485636711\n",
      "\n",
      "epoch: 1 \n",
      "batch: 100 out of: 485 \n",
      "average loss: 0.0272506233304739\n",
      "\n",
      "epoch: 1 \n",
      "batch: 101 out of: 485 \n",
      "average loss: 0.037125881761312485\n",
      "\n",
      "epoch: 1 \n",
      "batch: 102 out of: 485 \n",
      "average loss: 0.05060623958706856\n",
      "\n",
      "epoch: 1 \n",
      "batch: 103 out of: 485 \n",
      "average loss: 0.029767895117402077\n",
      "\n",
      "epoch: 1 \n",
      "batch: 104 out of: 485 \n",
      "average loss: 0.05267550051212311\n",
      "\n",
      "epoch: 1 \n",
      "batch: 105 out of: 485 \n",
      "average loss: 0.0326642282307148\n",
      "\n",
      "epoch: 1 \n",
      "batch: 106 out of: 485 \n",
      "average loss: 0.04982181638479233\n",
      "\n",
      "epoch: 1 \n",
      "batch: 107 out of: 485 \n",
      "average loss: 0.039752546697854996\n",
      "\n",
      "epoch: 1 \n",
      "batch: 108 out of: 485 \n",
      "average loss: 0.031641073524951935\n",
      "\n",
      "epoch: 1 \n",
      "batch: 109 out of: 485 \n",
      "average loss: 0.08439735323190689\n",
      "\n",
      "epoch: 1 \n",
      "batch: 110 out of: 485 \n",
      "average loss: 0.03511178866028786\n",
      "\n",
      "epoch: 1 \n",
      "batch: 111 out of: 485 \n",
      "average loss: 0.041034288704395294\n",
      "\n",
      "epoch: 1 \n",
      "batch: 112 out of: 485 \n",
      "average loss: 0.08871782571077347\n",
      "\n",
      "epoch: 1 \n",
      "batch: 113 out of: 485 \n",
      "average loss: 0.022088175639510155\n",
      "\n",
      "epoch: 1 \n",
      "batch: 114 out of: 485 \n",
      "average loss: 0.0715186595916748\n",
      "\n",
      "epoch: 1 \n",
      "batch: 115 out of: 485 \n",
      "average loss: 0.020974228158593178\n",
      "\n",
      "epoch: 1 \n",
      "batch: 116 out of: 485 \n",
      "average loss: 0.010526775382459164\n",
      "\n",
      "epoch: 1 \n",
      "batch: 117 out of: 485 \n",
      "average loss: 0.04835377633571625\n",
      "\n",
      "epoch: 1 \n",
      "batch: 118 out of: 485 \n",
      "average loss: 0.07422782480716705\n",
      "\n",
      "epoch: 1 \n",
      "batch: 119 out of: 485 \n",
      "average loss: 0.04735507071018219\n",
      "\n",
      "epoch: 1 \n",
      "batch: 120 out of: 485 \n",
      "average loss: 0.0197468064725399\n",
      "\n",
      "epoch: 1 \n",
      "batch: 121 out of: 485 \n",
      "average loss: 0.08159016072750092\n",
      "\n",
      "epoch: 1 \n",
      "batch: 122 out of: 485 \n",
      "average loss: 0.1015089824795723\n",
      "\n",
      "epoch: 1 \n",
      "batch: 123 out of: 485 \n",
      "average loss: 0.0453965999186039\n",
      "\n",
      "epoch: 1 \n",
      "batch: 124 out of: 485 \n",
      "average loss: 0.11374735087156296\n",
      "\n",
      "epoch: 1 \n",
      "batch: 125 out of: 485 \n",
      "average loss: 0.033418480306863785\n",
      "\n",
      "epoch: 1 \n",
      "batch: 126 out of: 485 \n",
      "average loss: 0.03087775595486164\n",
      "\n",
      "epoch: 1 \n",
      "batch: 127 out of: 485 \n",
      "average loss: 0.019798194989562035\n",
      "\n",
      "epoch: 1 \n",
      "batch: 128 out of: 485 \n",
      "average loss: 0.02622481808066368\n",
      "\n",
      "epoch: 1 \n",
      "batch: 129 out of: 485 \n",
      "average loss: 0.03850496560335159\n",
      "\n",
      "epoch: 1 \n",
      "batch: 130 out of: 485 \n",
      "average loss: 0.023587120696902275\n",
      "\n",
      "epoch: 1 \n",
      "batch: 131 out of: 485 \n",
      "average loss: 0.030209051445126534\n",
      "\n",
      "epoch: 1 \n",
      "batch: 132 out of: 485 \n",
      "average loss: 0.03244836628437042\n",
      "\n",
      "epoch: 1 \n",
      "batch: 133 out of: 485 \n",
      "average loss: 0.03975342586636543\n",
      "\n",
      "epoch: 1 \n",
      "batch: 134 out of: 485 \n",
      "average loss: 0.03848648816347122\n",
      "\n",
      "epoch: 1 \n",
      "batch: 135 out of: 485 \n",
      "average loss: 0.00949879176914692\n",
      "\n",
      "epoch: 1 \n",
      "batch: 136 out of: 485 \n",
      "average loss: 0.027015460655093193\n",
      "\n",
      "epoch: 1 \n",
      "batch: 137 out of: 485 \n",
      "average loss: 0.020546214655041695\n",
      "\n",
      "epoch: 1 \n",
      "batch: 138 out of: 485 \n",
      "average loss: 0.04118083789944649\n",
      "\n",
      "epoch: 1 \n",
      "batch: 139 out of: 485 \n",
      "average loss: 0.044684652239084244\n",
      "\n",
      "epoch: 1 \n",
      "batch: 140 out of: 485 \n",
      "average loss: 0.02531507797539234\n",
      "\n",
      "epoch: 1 \n",
      "batch: 141 out of: 485 \n",
      "average loss: 0.02669510431587696\n",
      "\n",
      "epoch: 1 \n",
      "batch: 142 out of: 485 \n",
      "average loss: 0.023790232837200165\n",
      "\n",
      "epoch: 1 \n",
      "batch: 143 out of: 485 \n",
      "average loss: 0.020240947604179382\n",
      "\n",
      "epoch: 1 \n",
      "batch: 144 out of: 485 \n",
      "average loss: 0.04408441483974457\n",
      "\n",
      "epoch: 1 \n",
      "batch: 145 out of: 485 \n",
      "average loss: 0.033137548714876175\n",
      "\n",
      "epoch: 1 \n",
      "batch: 146 out of: 485 \n",
      "average loss: 0.02696426957845688\n",
      "\n",
      "epoch: 1 \n",
      "batch: 147 out of: 485 \n",
      "average loss: 0.042971618473529816\n",
      "\n",
      "epoch: 1 \n",
      "batch: 148 out of: 485 \n",
      "average loss: 0.1168704628944397\n",
      "\n",
      "epoch: 1 \n",
      "batch: 149 out of: 485 \n",
      "average loss: 0.015714872628450394\n",
      "\n",
      "epoch: 1 \n",
      "batch: 150 out of: 485 \n",
      "average loss: 0.031064694747328758\n",
      "\n",
      "epoch: 1 \n",
      "batch: 151 out of: 485 \n",
      "average loss: 0.04181322827935219\n",
      "\n",
      "epoch: 1 \n",
      "batch: 152 out of: 485 \n",
      "average loss: 0.025587543845176697\n",
      "\n",
      "epoch: 1 \n",
      "batch: 153 out of: 485 \n",
      "average loss: 0.022231144830584526\n",
      "\n",
      "epoch: 1 \n",
      "batch: 154 out of: 485 \n",
      "average loss: 0.02279042825102806\n",
      "\n",
      "epoch: 1 \n",
      "batch: 155 out of: 485 \n",
      "average loss: 0.028003724291920662\n",
      "\n",
      "epoch: 1 \n",
      "batch: 156 out of: 485 \n",
      "average loss: 0.040055323392152786\n",
      "\n",
      "epoch: 1 \n",
      "batch: 157 out of: 485 \n",
      "average loss: 0.020124616101384163\n",
      "\n",
      "epoch: 1 \n",
      "batch: 158 out of: 485 \n",
      "average loss: 0.04652593284845352\n",
      "\n",
      "epoch: 1 \n",
      "batch: 159 out of: 485 \n",
      "average loss: 0.04066735506057739\n",
      "\n",
      "epoch: 1 \n",
      "batch: 160 out of: 485 \n",
      "average loss: 0.024931250140070915\n",
      "\n",
      "epoch: 1 \n",
      "batch: 161 out of: 485 \n",
      "average loss: 0.02742702141404152\n",
      "\n",
      "epoch: 1 \n",
      "batch: 162 out of: 485 \n",
      "average loss: 0.025383220985531807\n",
      "\n",
      "epoch: 1 \n",
      "batch: 163 out of: 485 \n",
      "average loss: 0.0196485947817564\n",
      "\n",
      "epoch: 1 \n",
      "batch: 164 out of: 485 \n",
      "average loss: 0.08147189021110535\n",
      "\n",
      "epoch: 1 \n",
      "batch: 165 out of: 485 \n",
      "average loss: 0.016233500093221664\n",
      "\n",
      "epoch: 1 \n",
      "batch: 166 out of: 485 \n",
      "average loss: 0.029764996841549873\n",
      "\n",
      "epoch: 1 \n",
      "batch: 167 out of: 485 \n",
      "average loss: 0.02155756577849388\n",
      "\n",
      "epoch: 1 \n",
      "batch: 168 out of: 485 \n",
      "average loss: 0.02650049887597561\n",
      "\n",
      "epoch: 1 \n",
      "batch: 169 out of: 485 \n",
      "average loss: 0.0409381166100502\n",
      "\n",
      "epoch: 1 \n",
      "batch: 170 out of: 485 \n",
      "average loss: 0.015295056626200676\n",
      "\n",
      "epoch: 1 \n",
      "batch: 171 out of: 485 \n",
      "average loss: 0.03227032348513603\n",
      "\n",
      "epoch: 1 \n",
      "batch: 172 out of: 485 \n",
      "average loss: 0.02722090668976307\n",
      "\n",
      "epoch: 1 \n",
      "batch: 173 out of: 485 \n",
      "average loss: 0.052245642989873886\n",
      "\n",
      "epoch: 1 \n",
      "batch: 174 out of: 485 \n",
      "average loss: 0.014976998791098595\n",
      "\n",
      "epoch: 1 \n",
      "batch: 175 out of: 485 \n",
      "average loss: 0.021169573068618774\n",
      "\n",
      "epoch: 1 \n",
      "batch: 176 out of: 485 \n",
      "average loss: 0.01785346306860447\n",
      "\n",
      "epoch: 1 \n",
      "batch: 177 out of: 485 \n",
      "average loss: 0.03766297549009323\n",
      "\n",
      "epoch: 1 \n",
      "batch: 178 out of: 485 \n",
      "average loss: 0.04653916880488396\n",
      "\n",
      "epoch: 1 \n",
      "batch: 179 out of: 485 \n",
      "average loss: 0.027605758979916573\n",
      "\n",
      "epoch: 1 \n",
      "batch: 180 out of: 485 \n",
      "average loss: 0.02276468835771084\n",
      "\n",
      "epoch: 1 \n",
      "batch: 181 out of: 485 \n",
      "average loss: 0.017681825906038284\n",
      "\n",
      "epoch: 1 \n",
      "batch: 182 out of: 485 \n",
      "average loss: 0.04336576536297798\n",
      "\n",
      "epoch: 1 \n",
      "batch: 183 out of: 485 \n",
      "average loss: 0.03211800381541252\n",
      "\n",
      "epoch: 1 \n",
      "batch: 184 out of: 485 \n",
      "average loss: 0.026906538754701614\n",
      "\n",
      "epoch: 1 \n",
      "batch: 185 out of: 485 \n",
      "average loss: 0.02298138663172722\n",
      "\n",
      "epoch: 1 \n",
      "batch: 186 out of: 485 \n",
      "average loss: 0.02561611868441105\n",
      "\n",
      "epoch: 1 \n",
      "batch: 187 out of: 485 \n",
      "average loss: 0.023469766601920128\n",
      "\n",
      "epoch: 1 \n",
      "batch: 188 out of: 485 \n",
      "average loss: 0.08734910190105438\n",
      "\n",
      "epoch: 1 \n",
      "batch: 189 out of: 485 \n",
      "average loss: 0.04389951005578041\n",
      "\n",
      "epoch: 1 \n",
      "batch: 190 out of: 485 \n",
      "average loss: 0.03313067927956581\n",
      "\n",
      "epoch: 1 \n",
      "batch: 191 out of: 485 \n",
      "average loss: 0.0713505893945694\n",
      "\n",
      "epoch: 1 \n",
      "batch: 192 out of: 485 \n",
      "average loss: 0.1271332949399948\n",
      "\n",
      "epoch: 1 \n",
      "batch: 193 out of: 485 \n",
      "average loss: 0.03165493533015251\n",
      "\n",
      "epoch: 1 \n",
      "batch: 194 out of: 485 \n",
      "average loss: 0.0805719792842865\n",
      "\n",
      "epoch: 1 \n",
      "batch: 195 out of: 485 \n",
      "average loss: 0.0281173437833786\n",
      "\n",
      "epoch: 1 \n",
      "batch: 196 out of: 485 \n",
      "average loss: 0.045413680374622345\n",
      "\n",
      "epoch: 1 \n",
      "batch: 197 out of: 485 \n",
      "average loss: 0.03710675612092018\n",
      "\n",
      "epoch: 1 \n",
      "batch: 198 out of: 485 \n",
      "average loss: 0.01814856007695198\n",
      "\n",
      "epoch: 1 \n",
      "batch: 199 out of: 485 \n",
      "average loss: 0.05699910968542099\n",
      "\n",
      "epoch: 1 \n",
      "batch: 200 out of: 485 \n",
      "average loss: 0.02504274621605873\n",
      "\n",
      "epoch: 1 \n",
      "batch: 201 out of: 485 \n",
      "average loss: 0.02110746130347252\n",
      "\n",
      "epoch: 1 \n",
      "batch: 202 out of: 485 \n",
      "average loss: 0.06916790455579758\n",
      "\n",
      "epoch: 1 \n",
      "batch: 203 out of: 485 \n",
      "average loss: 0.03001558408141136\n",
      "\n",
      "epoch: 1 \n",
      "batch: 204 out of: 485 \n",
      "average loss: 0.03789409250020981\n",
      "\n",
      "epoch: 1 \n",
      "batch: 205 out of: 485 \n",
      "average loss: 0.03347226604819298\n",
      "\n",
      "epoch: 1 \n",
      "batch: 206 out of: 485 \n",
      "average loss: 0.028225859627127647\n",
      "\n",
      "epoch: 1 \n",
      "batch: 207 out of: 485 \n",
      "average loss: 0.03959742188453674\n",
      "\n",
      "epoch: 1 \n",
      "batch: 208 out of: 485 \n",
      "average loss: 0.04727404564619064\n",
      "\n",
      "epoch: 1 \n",
      "batch: 209 out of: 485 \n",
      "average loss: 0.025133421644568443\n",
      "\n",
      "epoch: 1 \n",
      "batch: 210 out of: 485 \n",
      "average loss: 0.04728066548705101\n",
      "\n",
      "epoch: 1 \n",
      "batch: 211 out of: 485 \n",
      "average loss: 0.02387296035885811\n",
      "\n",
      "epoch: 1 \n",
      "batch: 212 out of: 485 \n",
      "average loss: 0.027313638478517532\n",
      "\n",
      "epoch: 1 \n",
      "batch: 213 out of: 485 \n",
      "average loss: 0.03901867941021919\n",
      "\n",
      "epoch: 1 \n",
      "batch: 214 out of: 485 \n",
      "average loss: 0.19977311789989471\n",
      "\n",
      "epoch: 1 \n",
      "batch: 215 out of: 485 \n",
      "average loss: 0.0615834966301918\n",
      "\n",
      "epoch: 1 \n",
      "batch: 216 out of: 485 \n",
      "average loss: 0.018137890845537186\n",
      "\n",
      "epoch: 1 \n",
      "batch: 217 out of: 485 \n",
      "average loss: 0.024181436747312546\n",
      "\n",
      "epoch: 1 \n",
      "batch: 218 out of: 485 \n",
      "average loss: 0.015688296407461166\n",
      "\n",
      "epoch: 1 \n",
      "batch: 219 out of: 485 \n",
      "average loss: 0.02751077711582184\n",
      "\n",
      "epoch: 1 \n",
      "batch: 220 out of: 485 \n",
      "average loss: 0.032386306673288345\n",
      "\n",
      "epoch: 1 \n",
      "batch: 221 out of: 485 \n",
      "average loss: 0.02321508526802063\n",
      "\n",
      "epoch: 1 \n",
      "batch: 222 out of: 485 \n",
      "average loss: 0.03040626458823681\n",
      "\n",
      "epoch: 1 \n",
      "batch: 223 out of: 485 \n",
      "average loss: 0.020424379035830498\n",
      "\n",
      "epoch: 1 \n",
      "batch: 224 out of: 485 \n",
      "average loss: 0.018429696559906006\n",
      "\n",
      "epoch: 1 \n",
      "batch: 225 out of: 485 \n",
      "average loss: 0.02568882517516613\n",
      "\n",
      "epoch: 1 \n",
      "batch: 226 out of: 485 \n",
      "average loss: 0.0217939130961895\n",
      "\n",
      "epoch: 1 \n",
      "batch: 227 out of: 485 \n",
      "average loss: 0.017930997535586357\n",
      "\n",
      "epoch: 1 \n",
      "batch: 228 out of: 485 \n",
      "average loss: 0.020960045978426933\n",
      "\n",
      "epoch: 1 \n",
      "batch: 229 out of: 485 \n",
      "average loss: 0.013222766108810902\n",
      "\n",
      "epoch: 1 \n",
      "batch: 230 out of: 485 \n",
      "average loss: 0.026167042553424835\n",
      "\n",
      "epoch: 1 \n",
      "batch: 231 out of: 485 \n",
      "average loss: 0.019733699038624763\n",
      "\n",
      "epoch: 1 \n",
      "batch: 232 out of: 485 \n",
      "average loss: 0.023413091897964478\n",
      "\n",
      "epoch: 1 \n",
      "batch: 233 out of: 485 \n",
      "average loss: 0.030808502808213234\n",
      "\n",
      "epoch: 1 \n",
      "batch: 234 out of: 485 \n",
      "average loss: 0.03366510942578316\n",
      "\n",
      "epoch: 1 \n",
      "batch: 235 out of: 485 \n",
      "average loss: 0.019000913947820663\n",
      "\n",
      "epoch: 1 \n",
      "batch: 236 out of: 485 \n",
      "average loss: 0.023284247145056725\n",
      "\n",
      "epoch: 1 \n",
      "batch: 237 out of: 485 \n",
      "average loss: 0.015436280518770218\n",
      "\n",
      "epoch: 1 \n",
      "batch: 238 out of: 485 \n",
      "average loss: 0.01957668736577034\n",
      "\n",
      "epoch: 1 \n",
      "batch: 239 out of: 485 \n",
      "average loss: 0.01453268900513649\n",
      "\n",
      "epoch: 1 \n",
      "batch: 240 out of: 485 \n",
      "average loss: 0.030027372762560844\n",
      "\n",
      "epoch: 1 \n",
      "batch: 241 out of: 485 \n",
      "average loss: 0.0206015482544899\n",
      "\n",
      "epoch: 1 \n",
      "batch: 242 out of: 485 \n",
      "average loss: 0.02092020772397518\n",
      "\n",
      "epoch: 1 \n",
      "batch: 243 out of: 485 \n",
      "average loss: 0.02009938657283783\n",
      "\n",
      "epoch: 1 \n",
      "batch: 244 out of: 485 \n",
      "average loss: 0.03533677011728287\n",
      "\n",
      "epoch: 1 \n",
      "batch: 245 out of: 485 \n",
      "average loss: 0.02761516161262989\n",
      "\n",
      "epoch: 1 \n",
      "batch: 246 out of: 485 \n",
      "average loss: 0.02423456870019436\n",
      "\n",
      "epoch: 1 \n",
      "batch: 247 out of: 485 \n",
      "average loss: 0.03043118305504322\n",
      "\n",
      "epoch: 1 \n",
      "batch: 248 out of: 485 \n",
      "average loss: 0.017563490197062492\n",
      "\n",
      "epoch: 1 \n",
      "batch: 249 out of: 485 \n",
      "average loss: 0.023333385586738586\n",
      "\n",
      "epoch: 1 \n",
      "batch: 250 out of: 485 \n",
      "average loss: 0.02018655277788639\n",
      "\n",
      "epoch: 1 \n",
      "batch: 251 out of: 485 \n",
      "average loss: 0.019905827939510345\n",
      "\n",
      "epoch: 1 \n",
      "batch: 252 out of: 485 \n",
      "average loss: 0.019915523007512093\n",
      "\n",
      "epoch: 1 \n",
      "batch: 253 out of: 485 \n",
      "average loss: 0.015384018421173096\n",
      "\n",
      "epoch: 1 \n",
      "batch: 254 out of: 485 \n",
      "average loss: 0.05792466551065445\n",
      "\n",
      "epoch: 1 \n",
      "batch: 255 out of: 485 \n",
      "average loss: 0.02803896553814411\n",
      "\n",
      "epoch: 1 \n",
      "batch: 256 out of: 485 \n",
      "average loss: 0.01337379589676857\n",
      "\n",
      "epoch: 1 \n",
      "batch: 257 out of: 485 \n",
      "average loss: 0.021570634096860886\n",
      "\n",
      "epoch: 1 \n",
      "batch: 258 out of: 485 \n",
      "average loss: 0.022239532321691513\n",
      "\n",
      "epoch: 1 \n",
      "batch: 259 out of: 485 \n",
      "average loss: 0.01746179349720478\n",
      "\n",
      "epoch: 1 \n",
      "batch: 260 out of: 485 \n",
      "average loss: 0.009266968816518784\n",
      "\n",
      "epoch: 1 \n",
      "batch: 261 out of: 485 \n",
      "average loss: 0.01547648198902607\n",
      "\n",
      "epoch: 1 \n",
      "batch: 262 out of: 485 \n",
      "average loss: 0.01967597007751465\n",
      "\n",
      "epoch: 1 \n",
      "batch: 263 out of: 485 \n",
      "average loss: 0.04405295476317406\n",
      "\n",
      "epoch: 1 \n",
      "batch: 264 out of: 485 \n",
      "average loss: 0.02241562306880951\n",
      "\n",
      "epoch: 1 \n",
      "batch: 265 out of: 485 \n",
      "average loss: 0.02524847351014614\n",
      "\n",
      "epoch: 1 \n",
      "batch: 266 out of: 485 \n",
      "average loss: 0.007169163785874844\n",
      "\n",
      "epoch: 1 \n",
      "batch: 267 out of: 485 \n",
      "average loss: 0.017464280128479004\n",
      "\n",
      "epoch: 1 \n",
      "batch: 268 out of: 485 \n",
      "average loss: 0.015268991701304913\n",
      "\n",
      "epoch: 1 \n",
      "batch: 269 out of: 485 \n",
      "average loss: 0.015227897092700005\n",
      "\n",
      "epoch: 1 \n",
      "batch: 270 out of: 485 \n",
      "average loss: 0.017705809324979782\n",
      "\n",
      "epoch: 1 \n",
      "batch: 271 out of: 485 \n",
      "average loss: 0.030961228534579277\n",
      "\n",
      "epoch: 1 \n",
      "batch: 272 out of: 485 \n",
      "average loss: 0.018492888659238815\n",
      "\n",
      "epoch: 1 \n",
      "batch: 273 out of: 485 \n",
      "average loss: 0.015141608193516731\n",
      "\n",
      "epoch: 1 \n",
      "batch: 274 out of: 485 \n",
      "average loss: 0.014444099739193916\n",
      "\n",
      "epoch: 1 \n",
      "batch: 275 out of: 485 \n",
      "average loss: 0.012102331966161728\n",
      "\n",
      "epoch: 1 \n",
      "batch: 276 out of: 485 \n",
      "average loss: 0.018831240013241768\n",
      "\n",
      "epoch: 1 \n",
      "batch: 277 out of: 485 \n",
      "average loss: 0.01308154221624136\n",
      "\n",
      "epoch: 1 \n",
      "batch: 278 out of: 485 \n",
      "average loss: 0.014487979002296925\n",
      "\n",
      "epoch: 1 \n",
      "batch: 279 out of: 485 \n",
      "average loss: 0.01064275112003088\n",
      "\n",
      "epoch: 1 \n",
      "batch: 280 out of: 485 \n",
      "average loss: 0.02086125873029232\n",
      "\n",
      "epoch: 1 \n",
      "batch: 281 out of: 485 \n",
      "average loss: 0.020389797165989876\n",
      "\n",
      "epoch: 1 \n",
      "batch: 282 out of: 485 \n",
      "average loss: 0.01444645319133997\n",
      "\n",
      "epoch: 1 \n",
      "batch: 283 out of: 485 \n",
      "average loss: 0.01995187997817993\n",
      "\n",
      "epoch: 1 \n",
      "batch: 284 out of: 485 \n",
      "average loss: 0.018141040578484535\n",
      "\n",
      "epoch: 1 \n",
      "batch: 285 out of: 485 \n",
      "average loss: 0.014196328818798065\n",
      "\n",
      "epoch: 1 \n",
      "batch: 286 out of: 485 \n",
      "average loss: 0.015591349452733994\n",
      "\n",
      "epoch: 1 \n",
      "batch: 287 out of: 485 \n",
      "average loss: 0.05079428479075432\n",
      "\n",
      "epoch: 1 \n",
      "batch: 288 out of: 485 \n",
      "average loss: 0.02149955928325653\n",
      "\n",
      "epoch: 1 \n",
      "batch: 289 out of: 485 \n",
      "average loss: 0.02276039682328701\n",
      "\n",
      "epoch: 1 \n",
      "batch: 290 out of: 485 \n",
      "average loss: 0.013841214589774609\n",
      "\n",
      "epoch: 1 \n",
      "batch: 291 out of: 485 \n",
      "average loss: 0.019348852336406708\n",
      "\n",
      "epoch: 1 \n",
      "batch: 292 out of: 485 \n",
      "average loss: 0.0155892763286829\n",
      "\n",
      "epoch: 1 \n",
      "batch: 293 out of: 485 \n",
      "average loss: 0.011945551261305809\n",
      "\n",
      "epoch: 1 \n",
      "batch: 294 out of: 485 \n",
      "average loss: 0.01053959783166647\n",
      "\n",
      "epoch: 1 \n",
      "batch: 295 out of: 485 \n",
      "average loss: 0.01774802803993225\n",
      "\n",
      "epoch: 1 \n",
      "batch: 296 out of: 485 \n",
      "average loss: 0.01393057405948639\n",
      "\n",
      "epoch: 1 \n",
      "batch: 297 out of: 485 \n",
      "average loss: 0.01864645816385746\n",
      "\n",
      "epoch: 1 \n",
      "batch: 298 out of: 485 \n",
      "average loss: 0.011375615373253822\n",
      "\n",
      "epoch: 1 \n",
      "batch: 299 out of: 485 \n",
      "average loss: 0.02818911336362362\n",
      "\n",
      "epoch: 1 \n",
      "batch: 300 out of: 485 \n",
      "average loss: 0.012903843075037003\n",
      "\n",
      "epoch: 1 \n",
      "batch: 301 out of: 485 \n",
      "average loss: 0.012900718487799168\n",
      "\n",
      "epoch: 1 \n",
      "batch: 302 out of: 485 \n",
      "average loss: 0.012708158232271671\n",
      "\n",
      "epoch: 1 \n",
      "batch: 303 out of: 485 \n",
      "average loss: 0.019261885434389114\n",
      "\n",
      "epoch: 1 \n",
      "batch: 304 out of: 485 \n",
      "average loss: 0.022554690018296242\n",
      "\n",
      "epoch: 1 \n",
      "batch: 305 out of: 485 \n",
      "average loss: 0.014971557073295116\n",
      "\n",
      "epoch: 1 \n",
      "batch: 306 out of: 485 \n",
      "average loss: 0.010515707544982433\n",
      "\n",
      "epoch: 1 \n",
      "batch: 307 out of: 485 \n",
      "average loss: 0.010226857848465443\n",
      "\n",
      "epoch: 1 \n",
      "batch: 308 out of: 485 \n",
      "average loss: 0.010957427322864532\n",
      "\n",
      "epoch: 1 \n",
      "batch: 309 out of: 485 \n",
      "average loss: 0.007248551119118929\n",
      "\n",
      "epoch: 1 \n",
      "batch: 310 out of: 485 \n",
      "average loss: 0.018741177394986153\n",
      "\n",
      "epoch: 1 \n",
      "batch: 311 out of: 485 \n",
      "average loss: 0.06058378890156746\n",
      "\n",
      "epoch: 1 \n",
      "batch: 312 out of: 485 \n",
      "average loss: 0.0101542379707098\n",
      "\n",
      "epoch: 1 \n",
      "batch: 313 out of: 485 \n",
      "average loss: 0.020066069439053535\n",
      "\n",
      "epoch: 1 \n",
      "batch: 314 out of: 485 \n",
      "average loss: 0.01962640881538391\n",
      "\n",
      "epoch: 1 \n",
      "batch: 315 out of: 485 \n",
      "average loss: 0.016439568251371384\n",
      "\n",
      "epoch: 1 \n",
      "batch: 316 out of: 485 \n",
      "average loss: 0.013764554634690285\n",
      "\n",
      "epoch: 1 \n",
      "batch: 317 out of: 485 \n",
      "average loss: 0.014008399099111557\n",
      "\n",
      "epoch: 1 \n",
      "batch: 318 out of: 485 \n",
      "average loss: 0.016958177089691162\n",
      "\n",
      "epoch: 1 \n",
      "batch: 319 out of: 485 \n",
      "average loss: 0.01387323159724474\n",
      "\n",
      "epoch: 1 \n",
      "batch: 320 out of: 485 \n",
      "average loss: 0.020171793177723885\n",
      "\n",
      "epoch: 1 \n",
      "batch: 321 out of: 485 \n",
      "average loss: 0.008965478278696537\n",
      "\n",
      "epoch: 1 \n",
      "batch: 322 out of: 485 \n",
      "average loss: 0.012259156443178654\n",
      "\n",
      "epoch: 1 \n",
      "batch: 323 out of: 485 \n",
      "average loss: 0.014978017657995224\n",
      "\n",
      "epoch: 1 \n",
      "batch: 324 out of: 485 \n",
      "average loss: 0.008900012820959091\n",
      "\n",
      "epoch: 1 \n",
      "batch: 325 out of: 485 \n",
      "average loss: 0.014998199418187141\n",
      "\n",
      "epoch: 1 \n",
      "batch: 326 out of: 485 \n",
      "average loss: 0.010812013410031796\n",
      "\n",
      "epoch: 1 \n",
      "batch: 327 out of: 485 \n",
      "average loss: 0.009121110662817955\n",
      "\n",
      "epoch: 1 \n",
      "batch: 328 out of: 485 \n",
      "average loss: 0.010711771436035633\n",
      "\n",
      "epoch: 1 \n",
      "batch: 329 out of: 485 \n",
      "average loss: 0.016645798459649086\n",
      "\n",
      "epoch: 1 \n",
      "batch: 330 out of: 485 \n",
      "average loss: 0.00743749737739563\n",
      "\n",
      "epoch: 1 \n",
      "batch: 331 out of: 485 \n",
      "average loss: 0.008386031724512577\n",
      "\n",
      "epoch: 1 \n",
      "batch: 332 out of: 485 \n",
      "average loss: 0.019154544919729233\n",
      "\n",
      "epoch: 1 \n",
      "batch: 333 out of: 485 \n",
      "average loss: 0.0133376345038414\n",
      "\n",
      "epoch: 1 \n",
      "batch: 334 out of: 485 \n",
      "average loss: 0.02158123254776001\n",
      "\n",
      "epoch: 1 \n",
      "batch: 335 out of: 485 \n",
      "average loss: 0.016695750877261162\n",
      "\n",
      "epoch: 1 \n",
      "batch: 336 out of: 485 \n",
      "average loss: 0.0367509089410305\n",
      "\n",
      "epoch: 1 \n",
      "batch: 337 out of: 485 \n",
      "average loss: 0.005041147582232952\n",
      "\n",
      "epoch: 1 \n",
      "batch: 338 out of: 485 \n",
      "average loss: 0.01482855062931776\n",
      "\n",
      "epoch: 1 \n",
      "batch: 339 out of: 485 \n",
      "average loss: 0.02466539293527603\n",
      "\n",
      "epoch: 1 \n",
      "batch: 340 out of: 485 \n",
      "average loss: 0.015245056711137295\n",
      "\n",
      "epoch: 1 \n",
      "batch: 341 out of: 485 \n",
      "average loss: 0.010514108464121819\n",
      "\n",
      "epoch: 1 \n",
      "batch: 342 out of: 485 \n",
      "average loss: 0.011371146887540817\n",
      "\n",
      "epoch: 1 \n",
      "batch: 343 out of: 485 \n",
      "average loss: 0.018919596448540688\n",
      "\n",
      "epoch: 1 \n",
      "batch: 344 out of: 485 \n",
      "average loss: 0.013846633955836296\n",
      "\n",
      "epoch: 1 \n",
      "batch: 345 out of: 485 \n",
      "average loss: 0.008295938372612\n",
      "\n",
      "epoch: 1 \n",
      "batch: 346 out of: 485 \n",
      "average loss: 0.008159629069268703\n",
      "\n",
      "epoch: 1 \n",
      "batch: 347 out of: 485 \n",
      "average loss: 0.014545316807925701\n",
      "\n",
      "epoch: 1 \n",
      "batch: 348 out of: 485 \n",
      "average loss: 0.010580084286630154\n",
      "\n",
      "epoch: 1 \n",
      "batch: 349 out of: 485 \n",
      "average loss: 0.011860004626214504\n",
      "\n",
      "epoch: 1 \n",
      "batch: 350 out of: 485 \n",
      "average loss: 0.012123705819249153\n",
      "\n",
      "epoch: 1 \n",
      "batch: 351 out of: 485 \n",
      "average loss: 0.008668268099427223\n",
      "\n",
      "epoch: 1 \n",
      "batch: 352 out of: 485 \n",
      "average loss: 0.00930374301970005\n",
      "\n",
      "epoch: 1 \n",
      "batch: 353 out of: 485 \n",
      "average loss: 0.009260820224881172\n",
      "\n",
      "epoch: 1 \n",
      "batch: 354 out of: 485 \n",
      "average loss: 0.013045897707343102\n",
      "\n",
      "epoch: 1 \n",
      "batch: 355 out of: 485 \n",
      "average loss: 0.007349091116338968\n",
      "\n",
      "epoch: 1 \n",
      "batch: 356 out of: 485 \n",
      "average loss: 0.013835586607456207\n",
      "\n",
      "epoch: 1 \n",
      "batch: 357 out of: 485 \n",
      "average loss: 0.007294366601854563\n",
      "\n",
      "epoch: 1 \n",
      "batch: 358 out of: 485 \n",
      "average loss: 0.01167815737426281\n",
      "\n",
      "epoch: 1 \n",
      "batch: 359 out of: 485 \n",
      "average loss: 0.01009047869592905\n",
      "\n",
      "epoch: 1 \n",
      "batch: 360 out of: 485 \n",
      "average loss: 0.00889855157583952\n",
      "\n",
      "epoch: 1 \n",
      "batch: 361 out of: 485 \n",
      "average loss: 0.006041185464709997\n",
      "\n",
      "epoch: 1 \n",
      "batch: 362 out of: 485 \n",
      "average loss: 0.012573730200529099\n",
      "\n",
      "epoch: 1 \n",
      "batch: 363 out of: 485 \n",
      "average loss: 0.006670989096164703\n",
      "\n",
      "epoch: 1 \n",
      "batch: 364 out of: 485 \n",
      "average loss: 0.006982347462326288\n",
      "\n",
      "epoch: 1 \n",
      "batch: 365 out of: 485 \n",
      "average loss: 0.008536706678569317\n",
      "\n",
      "epoch: 1 \n",
      "batch: 366 out of: 485 \n",
      "average loss: 0.009819261729717255\n",
      "\n",
      "epoch: 1 \n",
      "batch: 367 out of: 485 \n",
      "average loss: 0.0020699601154774427\n",
      "\n",
      "epoch: 1 \n",
      "batch: 368 out of: 485 \n",
      "average loss: 0.00826326198875904\n",
      "\n",
      "epoch: 1 \n",
      "batch: 369 out of: 485 \n",
      "average loss: 0.010202785953879356\n",
      "\n",
      "epoch: 1 \n",
      "batch: 370 out of: 485 \n",
      "average loss: 0.013229184783995152\n",
      "\n",
      "epoch: 1 \n",
      "batch: 371 out of: 485 \n",
      "average loss: 0.01533644087612629\n",
      "\n",
      "epoch: 1 \n",
      "batch: 372 out of: 485 \n",
      "average loss: 0.006950387265533209\n",
      "\n",
      "epoch: 1 \n",
      "batch: 373 out of: 485 \n",
      "average loss: 0.010772041976451874\n",
      "\n",
      "epoch: 1 \n",
      "batch: 374 out of: 485 \n",
      "average loss: 0.009668090380728245\n",
      "\n",
      "epoch: 1 \n",
      "batch: 375 out of: 485 \n",
      "average loss: 0.010904881171882153\n",
      "\n",
      "epoch: 1 \n",
      "batch: 376 out of: 485 \n",
      "average loss: 0.012846923433244228\n",
      "\n",
      "epoch: 1 \n",
      "batch: 377 out of: 485 \n",
      "average loss: 0.006170989479869604\n",
      "\n",
      "epoch: 1 \n",
      "batch: 378 out of: 485 \n",
      "average loss: 0.0065415226854383945\n",
      "\n",
      "epoch: 1 \n",
      "batch: 379 out of: 485 \n",
      "average loss: 0.007950197905302048\n",
      "\n",
      "epoch: 1 \n",
      "batch: 380 out of: 485 \n",
      "average loss: 0.011277268640697002\n",
      "\n",
      "epoch: 1 \n",
      "batch: 381 out of: 485 \n",
      "average loss: 0.009259799495339394\n",
      "\n",
      "epoch: 1 \n",
      "batch: 382 out of: 485 \n",
      "average loss: 0.00601863581687212\n",
      "\n",
      "epoch: 1 \n",
      "batch: 383 out of: 485 \n",
      "average loss: 0.003923974931240082\n",
      "\n",
      "epoch: 1 \n",
      "batch: 384 out of: 485 \n",
      "average loss: 0.008181100711226463\n",
      "\n",
      "epoch: 1 \n",
      "batch: 385 out of: 485 \n",
      "average loss: 0.059421587735414505\n",
      "\n",
      "epoch: 1 \n",
      "batch: 386 out of: 485 \n",
      "average loss: 0.00671958364546299\n",
      "\n",
      "epoch: 1 \n",
      "batch: 387 out of: 485 \n",
      "average loss: 0.005036810878664255\n",
      "\n",
      "epoch: 1 \n",
      "batch: 388 out of: 485 \n",
      "average loss: 0.005990301724523306\n",
      "\n",
      "epoch: 1 \n",
      "batch: 389 out of: 485 \n",
      "average loss: 0.0067024631425738335\n",
      "\n",
      "epoch: 1 \n",
      "batch: 390 out of: 485 \n",
      "average loss: 0.011401239782571793\n",
      "\n",
      "epoch: 1 \n",
      "batch: 391 out of: 485 \n",
      "average loss: 0.006357892882078886\n",
      "\n",
      "epoch: 1 \n",
      "batch: 392 out of: 485 \n",
      "average loss: 0.022216543555259705\n",
      "\n",
      "epoch: 1 \n",
      "batch: 393 out of: 485 \n",
      "average loss: 0.006761620752513409\n",
      "\n",
      "epoch: 1 \n",
      "batch: 394 out of: 485 \n",
      "average loss: 0.004052066244184971\n",
      "\n",
      "epoch: 1 \n",
      "batch: 395 out of: 485 \n",
      "average loss: 0.0060658566653728485\n",
      "\n",
      "epoch: 1 \n",
      "batch: 396 out of: 485 \n",
      "average loss: 0.0052804420702159405\n",
      "\n",
      "epoch: 1 \n",
      "batch: 397 out of: 485 \n",
      "average loss: 0.006352561060339212\n",
      "\n",
      "epoch: 1 \n",
      "batch: 398 out of: 485 \n",
      "average loss: 0.0072144269943237305\n",
      "\n",
      "epoch: 1 \n",
      "batch: 399 out of: 485 \n",
      "average loss: 0.0032622688449919224\n",
      "\n",
      "epoch: 1 \n",
      "batch: 400 out of: 485 \n",
      "average loss: 0.004672142677009106\n",
      "\n",
      "epoch: 1 \n",
      "batch: 401 out of: 485 \n",
      "average loss: 0.005117510911077261\n",
      "\n",
      "epoch: 1 \n",
      "batch: 402 out of: 485 \n",
      "average loss: 0.005167341325432062\n",
      "\n",
      "epoch: 1 \n",
      "batch: 403 out of: 485 \n",
      "average loss: 0.004696226678788662\n",
      "\n",
      "epoch: 1 \n",
      "batch: 404 out of: 485 \n",
      "average loss: 0.003380255540832877\n",
      "\n",
      "epoch: 1 \n",
      "batch: 405 out of: 485 \n",
      "average loss: 0.004205930512398481\n",
      "\n",
      "epoch: 1 \n",
      "batch: 406 out of: 485 \n",
      "average loss: 0.003568505635485053\n",
      "\n",
      "epoch: 1 \n",
      "batch: 407 out of: 485 \n",
      "average loss: 0.002424179343506694\n",
      "\n",
      "epoch: 1 \n",
      "batch: 408 out of: 485 \n",
      "average loss: 0.0045666988007724285\n",
      "\n",
      "epoch: 1 \n",
      "batch: 409 out of: 485 \n",
      "average loss: 0.004539353772997856\n",
      "\n",
      "epoch: 1 \n",
      "batch: 410 out of: 485 \n",
      "average loss: 0.0031754455994814634\n",
      "\n",
      "epoch: 1 \n",
      "batch: 411 out of: 485 \n",
      "average loss: 0.0027134683914482594\n",
      "\n",
      "epoch: 1 \n",
      "batch: 412 out of: 485 \n",
      "average loss: 0.0023721884936094284\n",
      "\n",
      "epoch: 1 \n",
      "batch: 413 out of: 485 \n",
      "average loss: 0.004224882926791906\n",
      "\n",
      "epoch: 1 \n",
      "batch: 414 out of: 485 \n",
      "average loss: 0.0038924128748476505\n",
      "\n",
      "epoch: 1 \n",
      "batch: 415 out of: 485 \n",
      "average loss: 0.004000026732683182\n",
      "\n",
      "epoch: 1 \n",
      "batch: 416 out of: 485 \n",
      "average loss: 0.006502625998109579\n",
      "\n",
      "epoch: 1 \n",
      "batch: 417 out of: 485 \n",
      "average loss: 0.003247483866289258\n",
      "\n",
      "epoch: 1 \n",
      "batch: 418 out of: 485 \n",
      "average loss: 0.011783859692513943\n",
      "\n",
      "epoch: 1 \n",
      "batch: 419 out of: 485 \n",
      "average loss: 0.004588005598634481\n",
      "\n",
      "epoch: 1 \n",
      "batch: 420 out of: 485 \n",
      "average loss: 0.004140056669712067\n",
      "\n",
      "epoch: 1 \n",
      "batch: 421 out of: 485 \n",
      "average loss: 0.0035216561518609524\n",
      "\n",
      "epoch: 1 \n",
      "batch: 422 out of: 485 \n",
      "average loss: 0.00244939629919827\n",
      "\n",
      "epoch: 1 \n",
      "batch: 423 out of: 485 \n",
      "average loss: 0.0026962633710354567\n",
      "\n",
      "epoch: 1 \n",
      "batch: 424 out of: 485 \n",
      "average loss: 0.0023928466252982616\n",
      "\n",
      "epoch: 1 \n",
      "batch: 425 out of: 485 \n",
      "average loss: 0.029599076136946678\n",
      "\n",
      "epoch: 1 \n",
      "batch: 426 out of: 485 \n",
      "average loss: 0.0021734880283474922\n",
      "\n",
      "epoch: 1 \n",
      "batch: 427 out of: 485 \n",
      "average loss: 0.0024881784338504076\n",
      "\n",
      "epoch: 1 \n",
      "batch: 428 out of: 485 \n",
      "average loss: 0.0023260994348675013\n",
      "\n",
      "epoch: 1 \n",
      "batch: 429 out of: 485 \n",
      "average loss: 0.0035188973415642977\n",
      "\n",
      "epoch: 1 \n",
      "batch: 430 out of: 485 \n",
      "average loss: 0.0017425586702302098\n",
      "\n",
      "epoch: 1 \n",
      "batch: 431 out of: 485 \n",
      "average loss: 0.002551476936787367\n",
      "\n",
      "epoch: 1 \n",
      "batch: 432 out of: 485 \n",
      "average loss: 0.0025442016776651144\n",
      "\n",
      "epoch: 1 \n",
      "batch: 433 out of: 485 \n",
      "average loss: 0.002250891411677003\n",
      "\n",
      "epoch: 1 \n",
      "batch: 434 out of: 485 \n",
      "average loss: 0.010138566605746746\n",
      "\n",
      "epoch: 1 \n",
      "batch: 435 out of: 485 \n",
      "average loss: 0.001478753169067204\n",
      "\n",
      "epoch: 1 \n",
      "batch: 436 out of: 485 \n",
      "average loss: 0.0025891046971082687\n",
      "\n",
      "epoch: 1 \n",
      "batch: 437 out of: 485 \n",
      "average loss: 0.003149612108245492\n",
      "\n",
      "epoch: 1 \n",
      "batch: 438 out of: 485 \n",
      "average loss: 0.0024123440962284803\n",
      "\n",
      "epoch: 1 \n",
      "batch: 439 out of: 485 \n",
      "average loss: 0.0026497263461351395\n",
      "\n",
      "epoch: 1 \n",
      "batch: 440 out of: 485 \n",
      "average loss: 0.003918680362403393\n",
      "\n",
      "epoch: 1 \n",
      "batch: 441 out of: 485 \n",
      "average loss: 0.002348668873310089\n",
      "\n",
      "epoch: 1 \n",
      "batch: 442 out of: 485 \n",
      "average loss: 0.0018848417093977332\n",
      "\n",
      "epoch: 1 \n",
      "batch: 443 out of: 485 \n",
      "average loss: 0.002133615780621767\n",
      "\n",
      "epoch: 1 \n",
      "batch: 444 out of: 485 \n",
      "average loss: 0.0015778148081153631\n",
      "\n",
      "epoch: 1 \n",
      "batch: 445 out of: 485 \n",
      "average loss: 0.0014803039375692606\n",
      "\n",
      "epoch: 1 \n",
      "batch: 446 out of: 485 \n",
      "average loss: 0.0017542950809001923\n",
      "\n",
      "epoch: 1 \n",
      "batch: 447 out of: 485 \n",
      "average loss: 0.0018284334801137447\n",
      "\n",
      "epoch: 1 \n",
      "batch: 448 out of: 485 \n",
      "average loss: 0.00254824454896152\n",
      "\n",
      "epoch: 1 \n",
      "batch: 449 out of: 485 \n",
      "average loss: 0.001208193600177765\n",
      "\n",
      "epoch: 1 \n",
      "batch: 450 out of: 485 \n",
      "average loss: 0.0020840317010879517\n",
      "\n",
      "epoch: 1 \n",
      "batch: 451 out of: 485 \n",
      "average loss: 0.0016216021031141281\n",
      "\n",
      "epoch: 1 \n",
      "batch: 452 out of: 485 \n",
      "average loss: 0.0013696005335077643\n",
      "\n",
      "epoch: 1 \n",
      "batch: 453 out of: 485 \n",
      "average loss: 0.0015367630403488874\n",
      "\n",
      "epoch: 1 \n",
      "batch: 454 out of: 485 \n",
      "average loss: 0.0021445865277200937\n",
      "\n",
      "epoch: 1 \n",
      "batch: 455 out of: 485 \n",
      "average loss: 0.0014794111484661698\n",
      "\n",
      "epoch: 1 \n",
      "batch: 456 out of: 485 \n",
      "average loss: 0.0008590599754825234\n",
      "\n",
      "epoch: 1 \n",
      "batch: 457 out of: 485 \n",
      "average loss: 0.0015807532472535968\n",
      "\n",
      "epoch: 1 \n",
      "batch: 458 out of: 485 \n",
      "average loss: 0.0019586270209401846\n",
      "\n",
      "epoch: 1 \n",
      "batch: 459 out of: 485 \n",
      "average loss: 0.0012223933590576053\n",
      "\n",
      "epoch: 1 \n",
      "batch: 460 out of: 485 \n",
      "average loss: 0.0016336011467501521\n",
      "\n",
      "epoch: 1 \n",
      "batch: 461 out of: 485 \n",
      "average loss: 0.0012598092434927821\n",
      "\n",
      "epoch: 1 \n",
      "batch: 462 out of: 485 \n",
      "average loss: 0.0008080368279479444\n",
      "\n",
      "epoch: 1 \n",
      "batch: 463 out of: 485 \n",
      "average loss: 0.0010673300130292773\n",
      "\n",
      "epoch: 1 \n",
      "batch: 464 out of: 485 \n",
      "average loss: 0.0010929048294201493\n",
      "\n",
      "epoch: 1 \n",
      "batch: 465 out of: 485 \n",
      "average loss: 0.0006749829044565558\n",
      "\n",
      "epoch: 1 \n",
      "batch: 466 out of: 485 \n",
      "average loss: 0.0010127178393304348\n",
      "\n",
      "epoch: 1 \n",
      "batch: 467 out of: 485 \n",
      "average loss: 0.0012120604515075684\n",
      "\n",
      "epoch: 1 \n",
      "batch: 468 out of: 485 \n",
      "average loss: 0.0007380102761089802\n",
      "\n",
      "epoch: 1 \n",
      "batch: 469 out of: 485 \n",
      "average loss: 0.0007639122195541859\n",
      "\n",
      "epoch: 1 \n",
      "batch: 470 out of: 485 \n",
      "average loss: 0.0009354170761071146\n",
      "\n",
      "epoch: 1 \n",
      "batch: 471 out of: 485 \n",
      "average loss: 0.0015350683825090528\n",
      "\n",
      "epoch: 1 \n",
      "batch: 472 out of: 485 \n",
      "average loss: 0.0005938900867477059\n",
      "\n",
      "epoch: 1 \n",
      "batch: 473 out of: 485 \n",
      "average loss: 0.0007887884275987744\n",
      "\n",
      "epoch: 1 \n",
      "batch: 474 out of: 485 \n",
      "average loss: 0.005053648725152016\n",
      "\n",
      "epoch: 1 \n",
      "batch: 475 out of: 485 \n",
      "average loss: 0.0008032225305214524\n",
      "\n",
      "epoch: 1 \n",
      "batch: 476 out of: 485 \n",
      "average loss: 0.058345891535282135\n",
      "\n",
      "epoch: 1 \n",
      "batch: 477 out of: 485 \n",
      "average loss: 0.0005088666803203523\n",
      "\n",
      "epoch: 1 \n",
      "batch: 478 out of: 485 \n",
      "average loss: 0.0006111693219281733\n",
      "\n",
      "epoch: 1 \n",
      "batch: 479 out of: 485 \n",
      "average loss: 0.0007946117548272014\n",
      "\n",
      "epoch: 1 \n",
      "batch: 480 out of: 485 \n",
      "average loss: 0.0011168194469064474\n",
      "\n",
      "epoch: 1 \n",
      "batch: 481 out of: 485 \n",
      "average loss: 0.0004756232665386051\n",
      "\n",
      "epoch: 1 \n",
      "batch: 482 out of: 485 \n",
      "average loss: 0.0007897726027294993\n",
      "\n",
      "epoch: 1 \n",
      "batch: 483 out of: 485 \n",
      "average loss: 0.0008489086758345366\n",
      "\n",
      "epoch: 1 \n",
      "batch: 484 out of: 485 \n",
      "average loss: 0.0005299657350406051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_batches = np.int64(np.floor(train_data.shape[0] / batch_size))\n",
    "'''TRAIN MODEL'''\n",
    "for i in range(num_epochs):\n",
    "    j = 0\n",
    "    for batch in np.array_split(train_data, num_batches):\n",
    "        batch_df = data.add_negatives(batch[['uid', 'mid', 'rating']], n_samples=4)\n",
    "        users = torch.LongTensor(batch_df.uid.to_numpy()).to(device)\n",
    "        items = torch.LongTensor(batch_df.mid.to_numpy()).to(device)\n",
    "        ratings = torch.FloatTensor(batch_df.rating.to_numpy()).to(device)\n",
    "        y_hat = preTrained_NCF(users, items)\n",
    "        loss = criterion(y_hat, ratings.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'epoch: {i + 1} \\nbatch: {j} out of: {num_batches} \\naverage loss: {loss.item()}\\n')\n",
    "        j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# %% model evaluation: hit rate and NDCG\n",
    "test_data = data.test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import heapq\n",
    "import math\n",
    "\n",
    "def evaluate_model(model, df_val:DataGenerator, top_K, random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val), top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val), top_K))\n",
    "\n",
    "    for i in range(len(df_val)):\n",
    "        test_df = data.add_negatives(df_val, n_samples=random_samples)\n",
    "        users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.mid).to(device)\n",
    "        y_hat = model(users, items)\n",
    "\n",
    "        y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "        test_item_input = items.cpu().detach().numpy().reshape((-1,))\n",
    "        map_item_score = {}\n",
    "        for j in range(len(y_hat)):\n",
    "            map_item_score[test_item_input[j]] = y_hat[j]\n",
    "        for k in range(top_K):\n",
    "            # Evaluate top rank list\n",
    "            ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "            gtItem = test_item_input[0]\n",
    "            for item in ranklist:\n",
    "                if item==gtItem:\n",
    "                    avg_HR[i, k] = 1\n",
    "                    avg_NDCG[i, k] = math.log(2) / math.log(i+2)\n",
    "                else:\n",
    "                    avg_HR[i, k] = 0\n",
    "                    avg_NDCG[i, k] = 0\n",
    "    avg_HR = np.mean(avg_HR, axis=0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis=0)\n",
    "    return avg_HR, avg_NDCG\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(preTrained_NCF.state_dict(), \"models/preTrained_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_HR_preTrain, avg_NDCG_preTrain = evaluate_model(preTrained_NCF, test_data, top_K, random_samples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# debiased_NCF = NCF(data.num_users, data.num_movies, emb_size, hidden_layers, output_size).to(device)\n",
    "# debiased_NCF.load_state_dict(torch.load(\"trained-models/preTrained_NCF\"))\n",
    "# debiased_NCF.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import constants\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def features():\n",
    "    df = pd.read_csv('MovieLens/users.dat',\n",
    "                     sep='::',\n",
    "                     header=None,\n",
    "                     names=['uid', 'gender', 'age', 'job', 'zip'],\n",
    "                     engine='python')\n",
    "    df.drop(columns=['uid'], inplace=True)\n",
    "    df.index.rename('uid', inplace=True)\n",
    "    df.gender = pd.get_dummies(df.gender, drop_first=True)  # 0:F, 1:M\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "features = features()\n",
    "\n",
    "# complete = pd.merge(df, data.df, how=' outer', on='uid')\n",
    "# complete.drop(columns=['date', 'latest', 'zip'], inplace=True)\n",
    "# gender_embed = compute_gender_direction(train_data, train_protected_attributes, users_embed)\n",
    "# S = 0 indicates male and S = 1 indicates female"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/j1jq_1qs78n4gd1vczc8vfw80000gn/T/ipykernel_6498/2444525869.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['rating'] = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "   uid  gender  age  job    zip  rating  njob\n0    1       1   56    0  70072       1     0\n1    2       1   25    1  55117       1     1\n2    3       1   45    2  02460       1     2\n3    4       1   25    3  55455       1     3\n4    5       0   50    4  55117       1     4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>job</th>\n      <th>zip</th>\n      <th>rating</th>\n      <th>njob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>56</td>\n      <td>0</td>\n      <td>70072</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>25</td>\n      <td>1</td>\n      <td>55117</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>45</td>\n      <td>2</td>\n      <td>02460</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>25</td>\n      <td>3</td>\n      <td>55455</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>50</td>\n      <td>4</td>\n      <td>55117</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see constants for more info\n",
    "drop = [0, 10, 13, 19]\n",
    "\n",
    "clean = features[~features['job'].isin(drop)]\n",
    "\n",
    "clean['rating'] = 1\n",
    "num_users = clean.uid.nunique()\n",
    "# num_movies = clean.mid.nunique()\n",
    "num_jobs = clean.job.nunique()\n",
    "\n",
    "new_job_index = np.arange(num_jobs)\n",
    "item_id = clean[['job']].drop_duplicates()\n",
    "item_id['njob'] = np.arange(num_jobs)\n",
    "clean = pd.merge(clean, item_id, on=['job'], how='left')\n",
    "clean.job = clean.njob\n",
    "clean.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4920 entries, 0 to 4919\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   uid     4920 non-null   int64 \n",
      " 1   gender  4920 non-null   uint8 \n",
      " 2   age     4920 non-null   int64 \n",
      " 3   job     4920 non-null   int64 \n",
      " 4   zip     4920 non-null   object\n",
      " 5   rating  4920 non-null   int64 \n",
      " 6   njob    4920 non-null   int64 \n",
      "dtypes: int64(5), object(1), uint8(1)\n",
      "memory usage: 273.9+ KB\n"
     ]
    }
   ],
   "source": [
    "msk = np.random.rand(len(clean)) < 0.7\n",
    "\n",
    "train = clean[msk]\n",
    "test = clean[~msk]\n",
    "\n",
    "clean.info()  # 1476+3444 = 4920\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "''' GET USER EMBEDDING '''\n",
    "user_embeds = preTrained_NCF.user_emb.weight.data.cpu().detach().numpy()\n",
    "user_embeds = user_embeds.astype('float')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "''' COMPUTE GENDER EMBEDDING '''\n",
    "gender_embed = np.zeros((2,user_embeds.shape[1]))\n",
    "num_users_x_group = np.zeros((2, 1))\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    u = train['uid'].iloc[i]\n",
    "    if train['gender'].iloc[i] == 0:\n",
    "        gender_embed[0] +=  user_embeds[u]\n",
    "        num_users_x_group[0] += 1.0\n",
    "    else:\n",
    "        gender_embed[1] +=  user_embeds[u]\n",
    "        gender_embed[1] += 1.0\n",
    "        num_users_x_group[1] += 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.09069008, 0.09003054, 0.08496672, 0.09050297, 0.08642624,\n        0.08902275, 0.08749835, 0.08371646, 0.08727884, 0.08833783,\n        0.08636001, 0.08821293, 0.08301546, 0.08872426, 0.08411755,\n        0.08561655, 0.09076883, 0.08932683, 0.08813156, 0.08828874,\n        0.08777421, 0.09261886, 0.09256089, 0.08925772, 0.08927288,\n        0.08415085, 0.09027174, 0.09163169, 0.08620748, 0.09127901,\n        0.08907101, 0.08760005, 0.0856063 , 0.08866908, 0.09112992,\n        0.09213509, 0.08922896, 0.09195355, 0.08909875, 0.086764  ,\n        0.09079708, 0.08806218, 0.08690775, 0.08625827, 0.08981551,\n        0.0859188 , 0.08947847, 0.08731626, 0.08268248, 0.09064306,\n        0.08455186, 0.08849131, 0.09175542, 0.08973892, 0.08846167,\n        0.08708216, 0.08771133, 0.08641088, 0.08827489, 0.08764957,\n        0.08548956, 0.09011761, 0.09402284, 0.08968159, 0.08752014,\n        0.08969738, 0.09025029, 0.08867402, 0.08841823, 0.08767961,\n        0.08769625, 0.08736225, 0.08915547, 0.08426079, 0.09271509,\n        0.08806927, 0.09101497, 0.08979937, 0.09037435, 0.08835041,\n        0.08655522, 0.09394497, 0.08701044, 0.08854157, 0.08524851,\n        0.09048104, 0.08573477, 0.09140739, 0.09072256, 0.08950535,\n        0.08560994, 0.0875136 , 0.09071034, 0.08825359, 0.08908221,\n        0.08869147, 0.08808796, 0.08496149, 0.08832145, 0.09075612,\n        0.08748962, 0.08511911, 0.09072151, 0.08805998, 0.08729928,\n        0.08673541, 0.08821809, 0.0874717 , 0.08037511, 0.08816107,\n        0.08888456, 0.09075878, 0.08919608, 0.08871714, 0.08555595,\n        0.08905633, 0.08712526, 0.08918621, 0.09118501, 0.09013134,\n        0.08479933, 0.08753041, 0.08709305, 0.08936132, 0.09216373,\n        0.08765116, 0.09052657, 0.0842677 ]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' VERTICAL BIAS'''\n",
    "gender_embed = gender_embed / num_users_x_group\n",
    "# vBias = compute_bias_direction(gender_embed)\n",
    "vBias = gender_embed[1].reshape((1,-1)) - gender_embed[0].reshape((1,-1))\n",
    "vBias = vBias / np.linalg.norm(vBias,axis=1,keepdims=1)\n",
    "\n",
    "vBias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "''' LINEAR PROJECTION '''\n",
    "debiased_user_embeds = user_embeds\n",
    "\n",
    "\n",
    "for i in range(len(clean)):\n",
    "    u = clean['uid'].iloc[i]\n",
    "    debiased_user_embeds[u] = user_embeds[u] - (np.inner(user_embeds[u].reshape(1,-1),vBias)[0][0])*vBias\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "'''UPDATE USER EMBEDDINGS'''\n",
    "fairness_thres = torch.tensor(0.1).to(device)\n",
    "epsilonBase = torch.tensor(0.0).to(device)\n",
    "\n",
    "n_careers = clean.job.nunique()\n",
    "# replace page items with career items\n",
    "preTrained_NCF.like_emb = nn.Embedding(n_careers,emb_size).to(device)\n",
    "# freeze user embedding\n",
    "preTrained_NCF.user_emb.weight.requires_grad=False\n",
    "\n",
    "# replace user embedding of the model with debiased embeddings\n",
    "preTrained_NCF.user_emb.weight.data = torch.from_numpy(debiased_user_embeds.astype(np.float32)).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% fine-tune to career recommendation\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "'''optimize'''\n",
    "# fair_fine_tune_model(DF_NCF,train_data, num_epochs, learning_rate,batch_size,num_negatives,n_careers,train_gender,fairness_thres,epsilonBase, unsqueeze=True)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(preTrained_NCF.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "\n",
    "preTrained_NCF.train()\n",
    "\n",
    "torch.save(preTrained_NCF.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  job  rating\n",
      "0    0    7       0\n",
      "1    0   10       0\n",
      "2    0   12       0\n",
      "3    0   14       0\n",
      "4    1    0       1\n",
      "tensor([ 7, 10, 12,  ...,  1,  5,  5])\n",
      "tensor(0.0662, grad_fn=<MeanBackward0>)\n",
      "epoch: 1 \n",
      "batch: 1 out of: 1 \n",
      "average loss: 47.4340705871582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_users = torch.LongTensor(train['uid'].values).to(device)\n",
    "all_items = torch.LongTensor(train['job'].values).to(device)\n",
    "all_genders = torch.LongTensor(train['gender'].values).to(device)\n",
    "\n",
    "from fairness_measures import Measures\n",
    "\n",
    "m = Measures()\n",
    "num_batches = np.int64(np.floor(train.shape[0] / batch_size))\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    j = 1\n",
    "    for batch in np.array_split(train, num_batches):\n",
    "        batch_df = data.add_negatives(\n",
    "            df=batch[['uid', 'job', 'rating']],\n",
    "            item='job',\n",
    "            items=set(clean.job.unique()),\n",
    "            n_samples=4\n",
    "        )\n",
    "        print(batch_df.head())\n",
    "        users = torch.LongTensor(batch_df.uid.to_numpy()).to(device)\n",
    "        items = torch.LongTensor(batch_df.job.to_numpy()).to(device)\n",
    "        ratings = torch.FloatTensor(batch_df.rating.to_numpy()).to(device)\n",
    "        print(items)\n",
    "        y_hat = preTrained_NCF(users, items)\n",
    "\n",
    "        loss1 = criterion(y_hat, ratings.unsqueeze(1))\n",
    "\n",
    "        predicted_probs = preTrained_NCF(all_users, all_items)\n",
    "        avg_epsilon = m.computeEDF(all_genders,predicted_probs,n_careers,all_items,device)\n",
    "        print(avg_epsilon)\n",
    "        #criteroin hinge\n",
    "        loss2 = torch.max(torch.tensor(0.0).to(device), (avg_epsilon-epsilonBase))\n",
    "\n",
    "        loss = loss1 + fairness_thres*loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'epoch: {i + 1} \\nbatch: {j} out of: {num_batches} \\naverage loss: {loss.item()}\\n')\n",
    "        j+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "torch.save(preTrained_NCF.state_dict(), \"models/DF_NCF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import heapq\n",
    "def evaluate_fine_tune(model,df_val,top_K,random_samples):\n",
    "    model.eval()\n",
    "    avg_HR = np.zeros((len(df_val),top_K))\n",
    "    avg_NDCG = np.zeros((len(df_val),top_K))\n",
    "\n",
    "    # for i in range(len(df_val)):\n",
    "    test_df = data.add_negatives(\n",
    "        df_val,\n",
    "        item='job',\n",
    "        items=set(clean.job.unique()),\n",
    "        n_samples=random_samples\n",
    "    )\n",
    "    users, items = torch.LongTensor(test_df.uid).to(device), torch.LongTensor(test_df.job).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    y_hat = y_hat.cpu().detach().numpy().reshape((-1,))\n",
    "    items = items.cpu().detach().numpy().reshape((-1,))\n",
    "    map_item_score = {}\n",
    "    for j in range(len(y_hat)):\n",
    "        map_item_score[items[j]] = y_hat[j]\n",
    "    for k in range(top_K):\n",
    "        # Evaluate top rank list\n",
    "        ranklist = heapq.nlargest(k, map_item_score, key=map_item_score.get)\n",
    "        gtItem = items[0]\n",
    "        avg_HR[i,k] = getHitRatio(ranklist, gtItem)\n",
    "        avg_NDCG[i,k] = getNDCG(ranklist, gtItem)\n",
    "    avg_HR = np.mean(avg_HR, axis = 0)\n",
    "    avg_NDCG = np.mean(avg_NDCG, axis = 0)\n",
    "    return avg_HR, avg_NDCG\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "emb_size = 128\n",
    "hidden_layers = np.array([emb_size, 64, 32, 16])\n",
    "output_size = 1\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "num_negatives = 5\n",
    "\n",
    "random_samples = 15\n",
    "top_K = 10\n",
    "\n",
    "avg_HR_DF_NCF, avg_NDCG_DF_NCF = evaluate_fine_tune(preTrained_NCF, test, top_K, random_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_HR_DF_NCF"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def fairness_measures(model,df_val,num_items):\n",
    "    model.eval()\n",
    "    users, items = torch.LongTensor(df_val.uid.to_numpy()).to(device), torch.LongTensor(df_val.job.to_numpy()).to(device)\n",
    "    y_hat = model(users, items)\n",
    "\n",
    "    avg_epsilon = m.computeEDF(all_genders,y_hat,num_items,items,device)\n",
    "    U_abs = m.compute_absolute_unfairness(all_genders,y_hat,num_items,items,device)\n",
    "\n",
    "    avg_epsilon = avg_epsilon.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"average differential fairness: {avg_epsilon: .3f}\")\n",
    "\n",
    "    U_abs = U_abs.cpu().detach().numpy().reshape((-1,)).item()\n",
    "    print(f\"absolute unfairness: {U_abs: .3f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average differential fairness:  0.188\n",
      "absolute unfairness:  0.081\n"
     ]
    }
   ],
   "source": [
    "fairness_measures(preTrained_NCF,test,n_careers)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}